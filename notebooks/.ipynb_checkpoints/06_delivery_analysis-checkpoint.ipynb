{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f247ddd",
   "metadata": {},
   "source": [
    "# 06_delivery_analysis.ipynb - CORRECTED VERSION\n",
    "\n",
    "## 1. Header\n",
    "\n",
    "**Title:** Delivery Performance Analysis  \n",
    "**Objective:** Analyze delivery performance, identify logistical bottlenecks, measure impact of delays on customer satisfaction, and optimize shipping cost-benefit ratio  \n",
    "**Date Created:** 2024-01-15  \n",
    "**Author:** Data Analyst  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1cfa074",
   "metadata": {},
   "source": [
    "## 2. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce3a21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from google.cloud import bigquery\n",
    "from google.oauth2 import service_account\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c8de79",
   "metadata": {},
   "source": [
    "## 3. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e93e30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project configuration - FIXED: Using relative path\n",
    "import os\n",
    "PROJECT_ID = 'quintoandar-ecommerce-analysis'\n",
    "\n",
    "# Use environment variable or relative path\n",
    "KEY_PATH = os.getenv('GOOGLE_APPLICATION_CREDENTIALS', \n",
    "                     'credentials/bigquery-key.json')\n",
    "\n",
    "# If using absolute path, ensure it works on any system\n",
    "# KEY_PATH = os.path.join(os.getcwd(), 'credentials', 'bigquery-key.json')\n",
    "\n",
    "print(f\"Using key path: {KEY_PATH}\")\n",
    "print(f\"Current working directory: {os.getcwd()}\")\n",
    "\n",
    "# Check if key file exists\n",
    "if not os.path.exists(KEY_PATH):\n",
    "    print(f\"WARNING: Key file not found at {KEY_PATH}\")\n",
    "    # Try alternative paths\n",
    "    alternative_paths = [\n",
    "        '../credentials/bigquery-key.json',\n",
    "        '../../credentials/bigquery-key.json',\n",
    "        './bigquery-key.json'\n",
    "    ]\n",
    "    for alt_path in alternative_paths:\n",
    "        if os.path.exists(alt_path):\n",
    "            KEY_PATH = alt_path\n",
    "            print(f\"Found key at: {KEY_PATH}\")\n",
    "            break\n",
    "\n",
    "# BigQuery client setup\n",
    "try:\n",
    "    credentials = service_account.Credentials.from_service_account_file(KEY_PATH)\n",
    "    client = bigquery.Client(credentials=credentials, project=PROJECT_ID)\n",
    "    print(\"BigQuery client initialized successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"Error initializing BigQuery client: {e}\")\n",
    "    # Fallback to default credentials if available\n",
    "    try:\n",
    "        client = bigquery.Client(project=PROJECT_ID)\n",
    "        print(\"Using default application credentials\")\n",
    "    except Exception as e2:\n",
    "        print(f\"Failed to initialize BigQuery: {e2}\")\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "\n",
    "# Create output directories - FIXED: Create directory before saving images\n",
    "os.makedirs(\"presentation/figures\", exist_ok=True)\n",
    "os.makedirs(\"exports\", exist_ok=True)\n",
    "print(\"Output directories created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bdee1e0",
   "metadata": {},
   "source": [
    "## 4. SQL Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e5da58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main query to extract delivery data\n",
    "delivery_query = \"\"\"\n",
    "SELECT \n",
    "    -- IDs\n",
    "    o.order_id,\n",
    "    o.customer_id,\n",
    "    c.customer_state,\n",
    "    c.customer_city,\n",
    "    \n",
    "    -- Dates\n",
    "    o.order_purchase_timestamp,\n",
    "    o.order_approved_at,\n",
    "    o.order_delivered_carrier_date,\n",
    "    o.order_delivered_customer_date,\n",
    "    o.order_estimated_delivery_date,\n",
    "    \n",
    "    -- Calculated times\n",
    "    DATE_DIFF(DATE(o.order_delivered_carrier_date), DATE(o.order_purchase_timestamp), DAY) as days_to_carrier,\n",
    "    DATE_DIFF(DATE(o.order_delivered_customer_date), DATE(o.order_delivered_carrier_date), DAY) as days_in_transit,\n",
    "    DATE_DIFF(DATE(o.order_delivered_customer_date), DATE(o.order_purchase_timestamp), DAY) as total_delivery_days,\n",
    "    DATE_DIFF(DATE(o.order_delivered_customer_date), DATE(o.order_estimated_delivery_date), DAY) as delay_days,\n",
    "    \n",
    "    -- SLA compliance\n",
    "    CASE \n",
    "        WHEN DATE(o.order_delivered_customer_date) <= DATE(o.order_estimated_delivery_date) THEN 1\n",
    "        ELSE 0\n",
    "    END as sla_compliant,\n",
    "    \n",
    "    CASE \n",
    "        WHEN DATE(o.order_delivered_customer_date) <= DATE(o.order_estimated_delivery_date) THEN 'On Time'\n",
    "        WHEN DATE_DIFF(DATE(o.order_delivered_customer_date), DATE(o.order_estimated_delivery_date), DAY) <= 5 THEN 'Slight Delay'\n",
    "        WHEN DATE_DIFF(DATE(o.order_delivered_customer_date), DATE(o.order_estimated_delivery_date), DAY) <= 15 THEN 'Moderate Delay'\n",
    "        ELSE 'Severe Delay'\n",
    "    END as delivery_status,\n",
    "    \n",
    "    -- Review\n",
    "    r.review_score,\n",
    "    r.review_comment_message,\n",
    "    \n",
    "    -- Freight\n",
    "    oi.freight_value,\n",
    "    oi.price as item_price,\n",
    "    SAFE_DIVIDE(oi.freight_value, oi.price) as freight_to_price_ratio,\n",
    "    \n",
    "    -- Region\n",
    "    CASE \n",
    "        WHEN c.customer_state IN ('SP', 'RJ', 'MG', 'ES') THEN 'Southeast'\n",
    "        WHEN c.customer_state IN ('RS', 'SC', 'PR') THEN 'South'\n",
    "        WHEN c.customer_state IN ('BA', 'PE', 'CE', 'MA', 'PB', 'RN', 'AL', 'SE', 'PI') THEN 'Northeast'\n",
    "        WHEN c.customer_state IN ('AM', 'PA', 'AC', 'RO', 'RR', 'AP', 'TO') THEN 'North'\n",
    "        WHEN c.customer_state IN ('GO', 'MT', 'MS', 'DF') THEN 'Central-West'\n",
    "        ELSE 'Other'\n",
    "    END as region\n",
    "    \n",
    "FROM `quintoandar-ecommerce-analysis.olist_staging.stg_orders` o\n",
    "LEFT JOIN `quintoandar-ecommerce-analysis.olist_staging.stg_customers` c \n",
    "    ON o.customer_id = c.customer_id\n",
    "LEFT JOIN `quintoandar-ecommerce-analysis.olist_staging.stg_reviews` r \n",
    "    ON o.order_id = r.order_id\n",
    "LEFT JOIN (\n",
    "    SELECT \n",
    "        order_id,\n",
    "        SUM(freight_value) as freight_value,\n",
    "        SUM(price) as price\n",
    "    FROM `quintoandar-ecommerce-analysis.olist_staging.stg_order_items`\n",
    "    GROUP BY order_id\n",
    ") oi ON o.order_id = oi.order_id\n",
    "\n",
    "WHERE o.order_status = 'delivered'\n",
    "AND o.order_delivered_customer_date IS NOT NULL\n",
    "AND o.order_estimated_delivery_date IS NOT NULL\n",
    "\"\"\"\n",
    "\n",
    "# Execute query\n",
    "print(\"Executing BigQuery...\")\n",
    "df = client.query(delivery_query).to_dataframe()\n",
    "print(f\"Dataset loaded: {len(df)} rows, {len(df.columns)} columns\")\n",
    "print(f\"Columns: {list(df.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78884ca",
   "metadata": {},
   "source": [
    "# 5. Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7f8e34",
   "metadata": {},
   "source": [
    "## 5.1 Setup & Imports Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7b2cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 50)\n",
    "print(\"SETUP VALIDATION\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# A) Check for empty dataset\n",
    "if len(df) == 0:\n",
    "    print(\"ERROR: Empty dataset loaded\")\n",
    "    # Create sample data for testing\n",
    "    print(\"Creating sample data for demonstration...\")\n",
    "    dates = pd.date_range('2023-01-01', '2023-12-31', freq='D')\n",
    "    df = pd.DataFrame({\n",
    "        'order_id': [f'order_{i}' for i in range(1000)],\n",
    "        'customer_state': np.random.choice(['SP', 'RJ', 'MG', 'RS', 'PR', 'BA'], 1000),\n",
    "        'total_delivery_days': np.random.normal(15, 5, 1000).clip(1, 30),\n",
    "        'delay_days': np.random.normal(2, 5, 1000),\n",
    "        'sla_compliant': np.random.choice([0, 1], 1000, p=[0.3, 0.7]),\n",
    "        'freight_value': np.random.uniform(10, 100, 1000),\n",
    "        'review_score': np.random.randint(1, 6, 1000)\n",
    "    })\n",
    "    print(f\"Created sample data: {len(df)} rows\")\n",
    "else:\n",
    "    print(f\"Dataset contains {len(df):,} valid records\")\n",
    "\n",
    "# B) Check critical columns\n",
    "required_cols = ['order_id', 'total_delivery_days', 'sla_compliant', 'delay_days']\n",
    "missing_cols = [col for col in required_cols if col not in df.columns]\n",
    "if missing_cols:\n",
    "    print(f\"ERROR: Missing critical columns: {missing_cols}\")\n",
    "    # Try to create missing columns if possible\n",
    "    if 'total_delivery_days' in missing_cols and 'delay_days' in missing_cols:\n",
    "        print(\"Attempting to calculate missing columns...\")\n",
    "        if 'order_delivered_customer_date' in df.columns and 'order_purchase_timestamp' in df.columns:\n",
    "            df['order_delivered_customer_date'] = pd.to_datetime(df['order_delivered_customer_date'])\n",
    "            df['order_purchase_timestamp'] = pd.to_datetime(df['order_purchase_timestamp'])\n",
    "            df['total_delivery_days'] = (df['order_delivered_customer_date'] - df['order_purchase_timestamp']).dt.days\n",
    "        if 'order_estimated_delivery_date' in df.columns:\n",
    "            df['order_estimated_delivery_date'] = pd.to_datetime(df['order_estimated_delivery_date'])\n",
    "            df['delay_days'] = (df['order_delivered_customer_date'] - df['order_estimated_delivery_date']).dt.days\n",
    "else:\n",
    "    print(\"SUCCESS: All required columns present\")\n",
    "\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274b12a7",
   "metadata": {},
   "source": [
    "## 5.2 Data Cleaning & Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a70f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"DATA CLEANING & VALIDATION\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "initial_count = len(df)\n",
    "print(f\"Initial record count: {initial_count:,}\")\n",
    "\n",
    "# C) Handle null values\n",
    "print(\"\\nHandling null values...\")\n",
    "if 'review_score' in df.columns:\n",
    "    review_median = df['review_score'].median()\n",
    "    null_reviews = df['review_score'].isna().sum()\n",
    "    df['review_score'] = df['review_score'].fillna(review_median)\n",
    "    print(f\"  Filled {null_reviews:,} null review scores with median: {review_median:.2f}\")\n",
    "\n",
    "if 'freight_value' in df.columns:\n",
    "    freight_median = df['freight_value'].median()\n",
    "    null_freight = df['freight_value'].isna().sum()\n",
    "    df['freight_value'] = df['freight_value'].fillna(freight_median)\n",
    "    print(f\"  Filled {null_freight:,} null freight values with median: R${freight_median:.2f}\")\n",
    "\n",
    "# D) Remove extreme outliers\n",
    "print(\"\\nRemoving extreme outliers...\")\n",
    "\n",
    "# Remove delivery times > 100 days (data errors)\n",
    "if 'total_delivery_days' in df.columns:\n",
    "    extreme_delivery = (df['total_delivery_days'] > 100).sum()\n",
    "    df = df[df['total_delivery_days'] <= 100]\n",
    "    df = df[df['total_delivery_days'] > 0]\n",
    "    print(f\"  Removed {extreme_delivery:,} records with delivery time > 100 days\")\n",
    "\n",
    "# Remove freight > 200 (extreme outliers)\n",
    "if 'freight_value' in df.columns:\n",
    "    extreme_freight = (df['freight_value'] > 200).sum()\n",
    "    df = df[df['freight_value'] <= 200]\n",
    "    df = df[df['freight_value'] > 0]\n",
    "    print(f\"  Removed {extreme_freight:,} records with freight > R$200\")\n",
    "\n",
    "# Remove delay < -30 days (date errors)\n",
    "if 'delay_days' in df.columns:\n",
    "    negative_delay = (df['delay_days'] < -30).sum()\n",
    "    df = df[df['delay_days'] >= -30]\n",
    "    print(f\"  Removed {negative_delay:,} records with delay < -30 days\")\n",
    "\n",
    "# E) Validate dates\n",
    "print(\"\\nValidating dates...\")\n",
    "date_columns = ['order_purchase_timestamp', 'order_delivered_customer_date']\n",
    "for col in date_columns:\n",
    "    if col in df.columns:\n",
    "        df[col] = pd.to_datetime(df[col], errors='coerce')\n",
    "        null_dates = df[col].isna().sum()\n",
    "        if null_dates > 0:\n",
    "            print(f\"  WARNING: {null_dates:,} null/invalid values in {col}\")\n",
    "\n",
    "# Remove invalid date sequences\n",
    "if 'order_delivered_customer_date' in df.columns and 'order_purchase_timestamp' in df.columns:\n",
    "    invalid_dates = (df['order_delivered_customer_date'] < df['order_purchase_timestamp']).sum()\n",
    "    df = df[df['order_delivered_customer_date'] >= df['order_purchase_timestamp']]\n",
    "    print(f\"  Removed {invalid_dates:,} records with invalid date sequence\")\n",
    "\n",
    "final_count = len(df)\n",
    "removed_count = initial_count - final_count\n",
    "print(f\"\\nCleaning summary:\")\n",
    "print(f\"  Initial records: {initial_count:,}\")\n",
    "print(f\"  Removed records: {removed_count:,}\")\n",
    "print(f\"  Final records: {final_count:,}\")\n",
    "print(f\"  Data retention: {(final_count/initial_count*100):.1f}%\")\n",
    "\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b06f338",
   "metadata": {},
   "source": [
    "## 5.3 Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200682f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"FEATURE ENGINEERING\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# A) Time features\n",
    "print(\"Creating time features...\")\n",
    "\n",
    "# Delay category\n",
    "if 'delay_days' in df.columns:\n",
    "    df['delay_category'] = pd.cut(\n",
    "        df['delay_days'],\n",
    "        bins=[-np.inf, 0, 5, 15, np.inf],\n",
    "        labels=['On Time', 'Slight Delay', 'Moderate Delay', 'Severe Delay']\n",
    "    )\n",
    "    print(f\"  Created delay_category with distribution:\")\n",
    "    print(df['delay_category'].value_counts(normalize=True).round(3))\n",
    "\n",
    "# Purchase weekday\n",
    "if 'order_purchase_timestamp' in df.columns:\n",
    "    df['purchase_weekday'] = pd.to_datetime(df['order_purchase_timestamp']).dt.day_name()\n",
    "    \n",
    "# Purchase month\n",
    "df['purchase_month'] = pd.to_datetime(df['order_purchase_timestamp']).dt.month\n",
    "df['purchase_year_month'] = pd.to_datetime(df['order_purchase_timestamp']).dt.to_period('M')\n",
    "\n",
    "print(f\"  Created purchase_weekday and purchase_month features\")\n",
    "\n",
    "# B) Cost features\n",
    "print(\"\\nCreating cost features...\")\n",
    "\n",
    "if 'freight_value' in df.columns and 'total_delivery_days' in df.columns:\n",
    "    df['freight_per_day'] = df['freight_value'] / df['total_delivery_days']\n",
    "    print(f\"  Created freight_per_day feature\")\n",
    "\n",
    "if 'freight_value' in df.columns:\n",
    "    freight_75th = df['freight_value'].quantile(0.75)\n",
    "    df['high_freight'] = (df['freight_value'] > freight_75th).astype(int)\n",
    "    print(f\"  Created high_freight flag (75th percentile: R${freight_75th:.2f})\")\n",
    "    \n",
    "    df['freight_category'] = pd.cut(\n",
    "        df['freight_value'],\n",
    "        bins=[0, 10, 20, 40, np.inf],\n",
    "        labels=['Low', 'Medium', 'High', 'Very High']\n",
    "    )\n",
    "    print(f\"  Created freight_category feature\")\n",
    "\n",
    "# C) Satisfaction features\n",
    "print(\"\\nCreating satisfaction features...\")\n",
    "\n",
    "if 'review_score' in df.columns:\n",
    "    df['positive_review'] = (df['review_score'] >= 4).astype(int)\n",
    "    df['negative_review'] = (df['review_score'] <= 2).astype(int)\n",
    "    df['has_review'] = df['review_score'].notna().astype(int)\n",
    "    \n",
    "    positive_pct = df['positive_review'].mean() * 100\n",
    "    negative_pct = df['negative_review'].mean() * 100\n",
    "    print(f\"  Created review features:\")\n",
    "    print(f\"    Positive reviews (>=4): {positive_pct:.1f}%\")\n",
    "    print(f\"    Negative reviews (<=2): {negative_pct:.1f}%\")\n",
    "\n",
    "print(f\"\\nFinal dataset shape: {df.shape}\")\n",
    "print(f\"Features created: {list(df.columns)}\")\n",
    "\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e33c7fd",
   "metadata": {},
   "source": [
    "## 5.4 Overall Delivery Performance (KPIs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ecedc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"OVERALL DELIVERY PERFORMANCE\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Calculate key metrics\n",
    "metrics = {}\n",
    "\n",
    "# Basic counts\n",
    "metrics['Total Orders'] = len(df)\n",
    "\n",
    "# SLA metrics\n",
    "if 'sla_compliant' in df.columns:\n",
    "    sla_rate = df['sla_compliant'].mean()\n",
    "    metrics['SLA Compliance Rate'] = f\"{sla_rate:.1%}\"\n",
    "    \n",
    "# Delivery time metrics\n",
    "if 'total_delivery_days' in df.columns:\n",
    "    avg_delivery = df['total_delivery_days'].mean()\n",
    "    metrics['Average Delivery Time'] = f\"{avg_delivery:.1f} days\"\n",
    "    \n",
    "# Delay metrics\n",
    "if 'delay_days' in df.columns:\n",
    "    avg_delay = df[df['delay_days'] > 0]['delay_days'].mean() if len(df[df['delay_days'] > 0]) > 0 else 0\n",
    "    delayed_orders = df[df['delay_days'] > 0].shape[0]\n",
    "    delayed_pct = delayed_orders / len(df) if len(df) > 0 else 0\n",
    "    metrics['Average Delay (when delayed)'] = f\"{avg_delay:.1f} days\"\n",
    "    metrics['Delayed Orders'] = f\"{delayed_orders:,} ({delayed_pct:.1%})\"\n",
    "    \n",
    "# Freight metrics\n",
    "if 'freight_value' in df.columns:\n",
    "    avg_freight = df['freight_value'].mean()\n",
    "    metrics['Average Freight'] = f\"R$ {avg_freight:.2f}\"\n",
    "    \n",
    "# Review metrics\n",
    "if 'review_score' in df.columns:\n",
    "    avg_review = df['review_score'].mean()\n",
    "    metrics['Average Review Score'] = f\"{avg_review:.2f}/5.0\"\n",
    "\n",
    "# Display metrics\n",
    "print(\"Key Performance Indicators:\")\n",
    "for metric, value in metrics.items():\n",
    "    print(f\"  {metric}: {value}\")\n",
    "\n",
    "# Create gauge chart for SLA compliance - FIXED: Directory already created\n",
    "fig = go.Figure(go.Indicator(\n",
    "    mode = \"gauge+number\",\n",
    "    value = sla_rate * 100,\n",
    "    title = {\"text\": \"SLA Compliance Rate (%)\"},\n",
    "    domain = {\"x\": [0, 1], \"y\": [0, 1]},\n",
    "    gauge = {\n",
    "        \"axis\": {\"range\": [0, 100]},\n",
    "        \"bar\": {\"color\": \"darkblue\"},\n",
    "        \"steps\": [\n",
    "            {\"range\": [0, 70], \"color\": \"red\"},\n",
    "            {\"range\": [70, 90], \"color\": \"yellow\"},\n",
    "            {\"range\": [90, 100], \"color\": \"green\"}\n",
    "        ],\n",
    "        \"threshold\": {\n",
    "            \"line\": {\"color\": \"black\", \"width\": 4},\n",
    "            \"thickness\": 0.75,\n",
    "            \"value\": 90\n",
    "        }\n",
    "    }\n",
    "))\n",
    "\n",
    "fig.update_layout(height=300, margin=dict(t=50, b=10, l=10, r=10))\n",
    "fig.show()\n",
    "\n",
    "# Save gauge chart\n",
    "fig.write_image(\"presentation/figures/sla_compliance_gauge.png\")\n",
    "print(\"Saved: presentation/figures/sla_compliance_gauge.png\")\n",
    "\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b08ab2b6",
   "metadata": {},
   "source": [
    "## 5.5 SLA Compliance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71acc848",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"SLA COMPLIANCE ANALYSIS\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# 1. SLA by region\n",
    "print(\"\\n1. SLA Compliance by Region:\")\n",
    "if 'region' in df.columns and 'sla_compliant' in df.columns:\n",
    "    sla_by_region = df.groupby('region')['sla_compliant'].mean().sort_values(ascending=False)\n",
    "    sla_by_region_df = sla_by_region.reset_index()\n",
    "    \n",
    "    print(sla_by_region_df.to_string(index=False))\n",
    "    \n",
    "    fig = px.bar(sla_by_region_df, \n",
    "                 x='region', \n",
    "                 y='sla_compliant',\n",
    "                 title='SLA Compliance by Region',\n",
    "                 labels={'sla_compliant': 'SLA Compliance Rate', 'region': 'Region'},\n",
    "                 color='sla_compliant',\n",
    "                 color_continuous_scale='Viridis')\n",
    "    \n",
    "    fig.update_layout(xaxis_tickangle=-45)\n",
    "    fig.show()\n",
    "    fig.write_image(\"presentation/figures/sla_by_region.png\")\n",
    "    print(\"Saved: presentation/figures/sla_by_region.png\")\n",
    "\n",
    "# 2. SLA trend by month\n",
    "print(\"\\n2. SLA Trend by Month:\")\n",
    "if 'purchase_month' in df.columns and 'sla_compliant' in df.columns:\n",
    "    sla_by_month = df.groupby('purchase_month')['sla_compliant'].mean().reset_index()\n",
    "    \n",
    "    print(sla_by_month.to_string(index=False))\n",
    "    \n",
    "    fig = px.line(sla_by_month, \n",
    "                  x='purchase_month', \n",
    "                  y='sla_compliant',\n",
    "                  title='SLA Compliance Trend by Month',\n",
    "                  labels={'sla_compliant': 'SLA Compliance Rate', 'purchase_month': 'Month'},\n",
    "                  markers=True)\n",
    "    \n",
    "    fig.update_layout(xaxis=dict(tickmode='linear', dtick=1))\n",
    "    fig.show()\n",
    "    fig.write_image(\"presentation/figures/sla_trend_monthly.png\")\n",
    "    print(\"Saved: presentation/figures/sla_trend_monthly.png\")\n",
    "\n",
    "# 3. Delivery status distribution\n",
    "print(\"\\n3. Delivery Status Distribution:\")\n",
    "if 'delivery_status' in df.columns:\n",
    "    status_dist = df['delivery_status'].value_counts(normalize=True).reset_index()\n",
    "    status_dist.columns = ['Delivery Status', 'Percentage']\n",
    "    status_dist['Percentage'] = (status_dist['Percentage'] * 100).round(1)\n",
    "    \n",
    "    print(status_dist.to_string(index=False))\n",
    "    \n",
    "    fig = px.pie(status_dist, \n",
    "                 values='Percentage', \n",
    "                 names='Delivery Status',\n",
    "                 title='Delivery Status Distribution',\n",
    "                 hole=0.3)\n",
    "    \n",
    "    fig.show()\n",
    "    fig.write_image(\"presentation/figures/delivery_status_distribution.png\")\n",
    "    print(\"Saved: presentation/figures/delivery_status_distribution.png\")\n",
    "\n",
    "# 4. Delay days distribution\n",
    "print(\"\\n4. Delay Days Distribution:\")\n",
    "if 'delay_days' in df.columns:\n",
    "    delay_stats = df['delay_days'].describe()\n",
    "    print(f\"Delay statistics:\")\n",
    "    print(f\"  Mean: {delay_stats['mean']:.2f} days\")\n",
    "    print(f\"  Median: {delay_stats['50%']:.2f} days\")\n",
    "    print(f\"  Std Dev: {delay_stats['std']:.2f} days\")\n",
    "    print(f\"  Min: {delay_stats['min']:.2f} days\")\n",
    "    print(f\"  Max: {delay_stats['max']:.2f} days\")\n",
    "    \n",
    "    fig = px.histogram(df, \n",
    "                       x='delay_days',\n",
    "                       nbins=50,\n",
    "                       title='Distribution of Delay Days',\n",
    "                       labels={'delay_days': 'Delay Days', 'count': 'Number of Orders'},\n",
    "                       opacity=0.7)\n",
    "    \n",
    "    fig.add_vline(x=0, line_dash=\"dash\", line_color=\"green\", annotation_text=\"On Time\")\n",
    "    fig.add_vline(x=df['delay_days'].mean(), line_dash=\"dash\", line_color=\"red\", annotation_text=\"Average Delay\")\n",
    "    fig.show()\n",
    "    fig.write_image(\"presentation/figures/delay_days_distribution.png\")\n",
    "    print(\"Saved: presentation/figures/delay_days_distribution.png\")\n",
    "\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1cdb7b6",
   "metadata": {},
   "source": [
    "## 5.6 Regional Delivery Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384394be",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"REGIONAL DELIVERY ANALYSIS\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Regional performance metrics\n",
    "if all(col in df.columns for col in ['region', 'order_id', 'total_delivery_days', 'delay_days', 'sla_compliant', 'freight_value', 'review_score']):\n",
    "    regional_analysis = df.groupby('region').agg({\n",
    "        'order_id': 'count',\n",
    "        'total_delivery_days': 'mean',\n",
    "        'delay_days': 'mean',\n",
    "        'sla_compliant': 'mean',\n",
    "        'freight_value': 'mean',\n",
    "        'review_score': 'mean'\n",
    "    }).round(2).reset_index()\n",
    "    \n",
    "    regional_analysis = regional_analysis.rename(columns={\n",
    "        'order_id': 'total_orders',\n",
    "        'total_delivery_days': 'avg_delivery_days',\n",
    "        'delay_days': 'avg_delay_days',\n",
    "        'sla_compliant': 'sla_rate',\n",
    "        'freight_value': 'avg_freight',\n",
    "        'review_score': 'avg_review_score'\n",
    "    })\n",
    "    \n",
    "    print(\"Regional Performance Analysis:\")\n",
    "    print(regional_analysis.to_string(index=False))\n",
    "    \n",
    "    # Identify worst performing regions\n",
    "    if not regional_analysis.empty:\n",
    "        worst_region_delivery = regional_analysis.loc[regional_analysis['avg_delivery_days'].idxmax(), 'region']\n",
    "        worst_region_sla = regional_analysis.loc[regional_analysis['sla_rate'].idxmin(), 'region']\n",
    "        best_region_sla = regional_analysis.loc[regional_analysis['sla_rate'].idxmax(), 'region']\n",
    "        \n",
    "        print(f\"\\nPerformance Highlights:\")\n",
    "        print(f\"  Best SLA region: {best_region_sla}\")\n",
    "        print(f\"  Worst SLA region: {worst_region_sla}\")\n",
    "        print(f\"  Longest delivery time: {worst_region_delivery}\")\n",
    "    \n",
    "    # Create grouped bar chart\n",
    "    fig = make_subplots(rows=2, cols=2,\n",
    "                        subplot_titles=('Average Delivery Days', 'SLA Compliance Rate',\n",
    "                                       'Average Freight Value', 'Average Review Score'))\n",
    "    \n",
    "    # Plot 1: Average Delivery Days\n",
    "    fig.add_trace(\n",
    "        go.Bar(x=regional_analysis['region'], y=regional_analysis['avg_delivery_days'],\n",
    "               name='Delivery Days', marker_color='blue'),\n",
    "        row=1, col=1\n",
    "    )\n",
    "    \n",
    "    # Plot 2: SLA Compliance Rate\n",
    "    fig.add_trace(\n",
    "        go.Bar(x=regional_analysis['region'], y=regional_analysis['sla_rate'],\n",
    "               name='SLA Rate', marker_color='green'),\n",
    "        row=1, col=2\n",
    "    )\n",
    "    \n",
    "    # Plot 3: Average Freight Value\n",
    "    fig.add_trace(\n",
    "        go.Bar(x=regional_analysis['region'], y=regional_analysis['avg_freight'],\n",
    "               name='Freight', marker_color='orange'),\n",
    "        row=2, col=1\n",
    "    )\n",
    "    \n",
    "    # Plot 4: Average Review Score\n",
    "    fig.add_trace(\n",
    "        go.Bar(x=regional_analysis['region'], y=regional_analysis['avg_review_score'],\n",
    "               name='Review Score', marker_color='purple'),\n",
    "        row=2, col=2\n",
    "    )\n",
    "    \n",
    "    fig.update_layout(height=600, showlegend=False, title_text=\"Regional Performance Metrics\")\n",
    "    fig.update_xaxes(tickangle=-45)\n",
    "    fig.show()\n",
    "    fig.write_image(\"presentation/figures/regional_performance_metrics.png\")\n",
    "    print(\"\\nSaved: presentation/figures/regional_performance_metrics.png\")\n",
    "    \n",
    "    # Box plot of delay days by region\n",
    "    fig = px.box(df, \n",
    "                 x='region', \n",
    "                 y='delay_days',\n",
    "                 title='Delay Days Distribution by Region',\n",
    "                 labels={'delay_days': 'Delay Days', 'region': 'Region'},\n",
    "                 color='region')\n",
    "    \n",
    "    fig.update_layout(xaxis_tickangle=-45)\n",
    "    fig.show()\n",
    "    fig.write_image(\"presentation/figures/delay_distribution_by_region.png\")\n",
    "    print(\"Saved: presentation/figures/delay_distribution_by_region.png\")\n",
    "\n",
    "# ADDITION: Brazil Heatmap - MISSING FROM ORIGINAL\n",
    "print(\"\\n5. Brazil Heatmap - Average Delay by State:\")\n",
    "if 'customer_state' in df.columns and 'delay_days' in df.columns:\n",
    "    state_delay = df.groupby('customer_state')['delay_days'].mean().reset_index()\n",
    "    \n",
    "    # Map Brazilian state codes to full names for better visualization\n",
    "    brazil_states = {\n",
    "        'AC': 'Acre', 'AL': 'Alagoas', 'AP': 'Amapá', 'AM': 'Amazonas',\n",
    "        'BA': 'Bahia', 'CE': 'Ceará', 'DF': 'Distrito Federal', 'ES': 'Espírito Santo',\n",
    "        'GO': 'Goiás', 'MA': 'Maranhão', 'MT': 'Mato Grosso', 'MS': 'Mato Grosso do Sul',\n",
    "        'MG': 'Minas Gerais', 'PA': 'Pará', 'PB': 'Paraíba', 'PR': 'Paraná',\n",
    "        'PE': 'Pernambuco', 'PI': 'Piauí', 'RJ': 'Rio de Janeiro', 'RN': 'Rio Grande do Norte',\n",
    "        'RS': 'Rio Grande do Sul', 'RO': 'Rondônia', 'RR': 'Roraima', 'SC': 'Santa Catarina',\n",
    "        'SP': 'São Paulo', 'SE': 'Sergipe', 'TO': 'Tocantins'\n",
    "    }\n",
    "    \n",
    "    state_delay['state_name'] = state_delay['customer_state'].map(brazil_states)\n",
    "    \n",
    "    fig = px.choropleth(\n",
    "        state_delay,\n",
    "        locations='customer_state',\n",
    "        locationmode='ISO-3',\n",
    "        color='delay_days',\n",
    "        hover_name='state_name',\n",
    "        scope='south america',\n",
    "        title='Average Delay Days by State (Brazil)',\n",
    "        color_continuous_scale='Reds',\n",
    "        labels={'delay_days': 'Avg Delay Days'}\n",
    "    )\n",
    "    \n",
    "    fig.update_geos(\n",
    "        center=dict(lat=-14, lon=-55),\n",
    "        lataxis_range=[-35, 5],\n",
    "        lonaxis_range=[-75, -30],\n",
    "        visible=False\n",
    "    )\n",
    "    \n",
    "    fig.update_layout(margin=dict(l=0, r=0, t=50, b=0))\n",
    "    fig.show()\n",
    "    fig.write_image(\"presentation/figures/brazil_heatmap_delays.png\")\n",
    "    print(\"Saved: presentation/figures/brazil_heatmap_delays.png\")\n",
    "\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0844ec0a",
   "metadata": {},
   "source": [
    "## 5.7 Delay Impact on Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec839661",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"DELAY IMPACT ON REVIEWS\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Correlation analysis\n",
    "if 'delay_days' in df.columns and 'review_score' in df.columns:\n",
    "    corr_delay_review = df['delay_days'].corr(df['review_score'])\n",
    "    print(f\"Correlation between delay days and review score: {corr_delay_review:.3f}\")\n",
    "    \n",
    "    # Interpret correlation\n",
    "    if abs(corr_delay_review) > 0.3:\n",
    "        strength = \"strong\"\n",
    "    elif abs(corr_delay_review) > 0.1:\n",
    "        strength = \"moderate\"\n",
    "    else:\n",
    "        strength = \"weak\"\n",
    "    \n",
    "    direction = \"negative\" if corr_delay_review < 0 else \"positive\"\n",
    "    print(f\"  Interpretation: {strength} {direction} correlation\")\n",
    "    \n",
    "    # Review score by delay category\n",
    "    if 'delivery_status' in df.columns:\n",
    "        review_by_delay = df.groupby('delivery_status')['review_score'].mean().reset_index()\n",
    "        review_by_delay = review_by_delay.sort_values('review_score', ascending=False)\n",
    "        \n",
    "        print(\"\\nAverage Review Score by Delivery Status:\")\n",
    "        print(review_by_delay.to_string(index=False))\n",
    "        \n",
    "        fig = px.bar(review_by_delay, \n",
    "                     x='delivery_status', \n",
    "                     y='review_score',\n",
    "                     title='Average Review Score by Delivery Status',\n",
    "                     labels={'review_score': 'Average Review Score', 'delivery_status': 'Delivery Status'},\n",
    "                     color='review_score',\n",
    "                     color_continuous_scale='RdYlGn')\n",
    "        \n",
    "        fig.update_layout(xaxis_tickangle=-45)\n",
    "        fig.show()\n",
    "        fig.write_image(\"presentation/figures/review_score_by_delivery_status.png\")\n",
    "        print(\"Saved: presentation/figures/review_score_by_delivery_status.png\")\n",
    "    \n",
    "    # Negative review percentage by delay category\n",
    "    if 'delivery_status' in df.columns and 'negative_review' in df.columns:\n",
    "        negative_by_delay = df.groupby('delivery_status')['negative_review'].mean().reset_index()\n",
    "        negative_by_delay = negative_by_delay.sort_values('negative_review', ascending=False)\n",
    "        \n",
    "        print(\"\\nNegative Review Percentage by Delivery Status:\")\n",
    "        negative_by_delay['negative_review'] = (negative_by_delay['negative_review'] * 100).round(1)\n",
    "        print(negative_by_delay.to_string(index=False))\n",
    "        \n",
    "        fig = px.bar(negative_by_delay, \n",
    "                     x='delivery_status', \n",
    "                     y='negative_review',\n",
    "                     title='Negative Review Percentage by Delivery Status',\n",
    "                     labels={'negative_review': 'Negative Review %', 'delivery_status': 'Delivery Status'},\n",
    "                     color='negative_review',\n",
    "                     color_continuous_scale='Reds')\n",
    "        \n",
    "        fig.update_layout(xaxis_tickangle=-45)\n",
    "        fig.show()\n",
    "        fig.write_image(\"presentation/figures/negative_reviews_by_delivery_status.png\")\n",
    "        print(\"Saved: presentation/figures/negative_reviews_by_delivery_status.png\")\n",
    "    \n",
    "    # Scatter plot with trendline\n",
    "    sample_size = min(1000, len(df))\n",
    "    fig = px.scatter(df.sample(n=sample_size, random_state=42), \n",
    "                     x='delay_days', \n",
    "                     y='review_score',\n",
    "                     title='Delay Days vs Review Score',\n",
    "                     labels={'delay_days': 'Delay Days', 'review_score': 'Review Score'},\n",
    "                     trendline='ols',\n",
    "                     opacity=0.5,\n",
    "                     trendline_color_override='red')\n",
    "    \n",
    "    fig.show()\n",
    "    fig.write_image(\"presentation/figures/delay_vs_review_scatter.png\")\n",
    "    print(\"Saved: presentation/figures/delay_vs_review_scatter.png\")\n",
    "    \n",
    "    # Linear regression for impact quantification\n",
    "    X = df[['delay_days']].fillna(0)\n",
    "    y = df['review_score'].fillna(df['review_score'].mean())\n",
    "    \n",
    "    model = LinearRegression()\n",
    "    model.fit(X, y)\n",
    "    \n",
    "    review_impact_per_day = model.coef_[0]\n",
    "    r_squared = model.score(X, y)\n",
    "    \n",
    "    print(f\"\\nLinear Regression Results:\")\n",
    "    print(f\"  Impact on review score per day of delay: {review_impact_per_day:.3f} points\")\n",
    "    print(f\"  R-squared: {r_squared:.3f}\")\n",
    "    print(f\"  Intercept: {model.intercept_:.3f}\")\n",
    "    \n",
    "    # Calculate predicted review scores\n",
    "    delay_values = [0, 5, 10, 15]\n",
    "    print(\"\\nPredicted Review Scores:\")\n",
    "    for delay in delay_values:\n",
    "        predicted_score = model.predict([[delay]])[0]\n",
    "        print(f\"  {delay} day delay: {predicted_score:.2f}/5.0\")\n",
    "else:\n",
    "    print(\"Required columns not available for delay-review analysis\")\n",
    "\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc83fa67",
   "metadata": {},
   "source": [
    "## 5.8 Freight Cost vs Time Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9724f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"FREIGHT COST VS TIME ANALYSIS\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Correlation analysis\n",
    "if 'freight_value' in df.columns and 'total_delivery_days' in df.columns:\n",
    "    corr_freight_time = df['freight_value'].corr(df['total_delivery_days'])\n",
    "    print(f\"Correlation between freight value and delivery time: {corr_freight_time:.3f}\")\n",
    "    \n",
    "    # Freight by delivery status\n",
    "    if 'delivery_status' in df.columns:\n",
    "        freight_by_status = df.groupby('delivery_status')['freight_value'].mean().reset_index()\n",
    "        freight_by_status = freight_by_status.sort_values('freight_value', ascending=False)\n",
    "        \n",
    "        print(\"\\nAverage Freight Value by Delivery Status:\")\n",
    "        print(freight_by_status.to_string(index=False))\n",
    "        \n",
    "        fig = px.bar(freight_by_status, \n",
    "                     x='delivery_status', \n",
    "                     y='freight_value',\n",
    "                     title='Average Freight Value by Delivery Status',\n",
    "                     labels={'freight_value': 'Average Freight (R$)', 'delivery_status': 'Delivery Status'},\n",
    "                     color='freight_value',\n",
    "                     color_continuous_scale='Blues')\n",
    "        \n",
    "        fig.update_layout(xaxis_tickangle=-45)\n",
    "        fig.show()\n",
    "        fig.write_image(\"presentation/figures/freight_by_delivery_status.png\")\n",
    "        print(\"Saved: presentation/figures/freight_by_delivery_status.png\")\n",
    "    \n",
    "    # Scatter plot with quadrants\n",
    "    sample_size = min(1000, len(df))\n",
    "    fig = px.scatter(df.sample(n=sample_size, random_state=42), \n",
    "                     x='total_delivery_days', \n",
    "                     y='freight_value',\n",
    "                     title='Freight Value vs Delivery Time',\n",
    "                     labels={'total_delivery_days': 'Total Delivery Days', 'freight_value': 'Freight Value (R$)'},\n",
    "                     opacity=0.5)\n",
    "    \n",
    "    # Add quadrant lines\n",
    "    avg_days = df['total_delivery_days'].mean()\n",
    "    avg_freight = df['freight_value'].mean()\n",
    "    \n",
    "    fig.add_hline(y=avg_freight, line_dash=\"dash\", line_color=\"red\", \n",
    "                  annotation_text=f\"Avg Freight: R${avg_freight:.2f}\")\n",
    "    fig.add_vline(x=avg_days, line_dash=\"dash\", line_color=\"red\", \n",
    "                  annotation_text=f\"Avg Days: {avg_days:.1f}\")\n",
    "    \n",
    "    fig.show()\n",
    "    fig.write_image(\"presentation/figures/freight_vs_delivery_time_scatter.png\")\n",
    "    print(\"Saved: presentation/figures/freight_vs_delivery_time_scatter.png\")\n",
    "    \n",
    "    # SLA compliance by freight category\n",
    "    if 'freight_category' in df.columns and 'sla_compliant' in df.columns:\n",
    "        sla_by_freight = df.groupby('freight_category')['sla_compliant'].mean().reset_index()\n",
    "        \n",
    "        print(\"\\nSLA Compliance by Freight Category:\")\n",
    "        print(sla_by_freight.to_string(index=False))\n",
    "        \n",
    "        fig = px.bar(sla_by_freight, \n",
    "                     x='freight_category', \n",
    "                     y='sla_compliant',\n",
    "                     title='SLA Compliance by Freight Category',\n",
    "                     labels={'sla_compliant': 'SLA Compliance Rate', 'freight_category': 'Freight Category'},\n",
    "                     color='sla_compliant',\n",
    "                     color_continuous_scale='Viridis')\n",
    "        \n",
    "        fig.update_layout(xaxis_tickangle=-45)\n",
    "        fig.show()\n",
    "        fig.write_image(\"presentation/figures/sla_by_freight_category.png\")\n",
    "        print(\"Saved: presentation/figures/sla_by_freight_category.png\")\n",
    "    \n",
    "    # ROI of premium freight\n",
    "    if 'high_freight' in df.columns and 'sla_compliant' in df.columns:\n",
    "        high_freight_sla = df[df['high_freight'] == 1]['sla_compliant'].mean()\n",
    "        low_freight_sla = df[df['high_freight'] == 0]['sla_compliant'].mean()\n",
    "        sla_improvement = high_freight_sla - low_freight_sla\n",
    "        \n",
    "        high_freight_avg = df[df['high_freight'] == 1]['freight_value'].mean()\n",
    "        low_freight_avg = df[df['high_freight'] == 0]['freight_value'].mean()\n",
    "        cost_difference = high_freight_avg - low_freight_avg\n",
    "        \n",
    "        print(f\"\\nFreight ROI Analysis:\")\n",
    "        print(f\"  SLA with high freight: {high_freight_sla:.1%}\")\n",
    "        print(f\"  SLA with low freight: {low_freight_sla:.1%}\")\n",
    "        print(f\"  SLA improvement with high freight: {sla_improvement:.1%} points\")\n",
    "        print(f\"  Average high freight cost: R${high_freight_avg:.2f}\")\n",
    "        print(f\"  Average low freight cost: R${low_freight_avg:.2f}\")\n",
    "        print(f\"  Cost difference: R${cost_difference:.2f}\")\n",
    "        \n",
    "        # Calculate cost per 1% SLA improvement\n",
    "        if sla_improvement > 0:\n",
    "            cost_per_sla_point = cost_difference / (sla_improvement * 100)\n",
    "            print(f\"  Cost per 1% SLA improvement: R${cost_per_sla_point:.2f}\")\n",
    "\n",
    "# ADDITION: 2x2 Cost vs Performance Matrix - MISSING FROM ORIGINAL\n",
    "print(\"\\n6. Cost vs Performance Matrix:\")\n",
    "if 'freight_value' in df.columns and 'sla_compliant' in df.columns:\n",
    "    median_freight = df['freight_value'].median()\n",
    "    median_sla = df['sla_compliant'].median()\n",
    "    \n",
    "    df['cost_performance_quadrant'] = 'Unknown'\n",
    "    df.loc[(df['freight_value'] > median_freight) & (df['sla_compliant'] > median_sla), 'cost_performance_quadrant'] = 'High Cost, High Performance'\n",
    "    df.loc[(df['freight_value'] > median_freight) & (df['sla_compliant'] <= median_sla), 'cost_performance_quadrant'] = 'High Cost, Low Performance'\n",
    "    df.loc[(df['freight_value'] <= median_freight) & (df['sla_compliant'] > median_sla), 'cost_performance_quadrant'] = 'Low Cost, High Performance'\n",
    "    df.loc[(df['freight_value'] <= median_freight) & (df['sla_compliant'] <= median_sla), 'cost_performance_quadrant'] = 'Low Cost, Low Performance'\n",
    "    \n",
    "    quadrant_summary = df['cost_performance_quadrant'].value_counts()\n",
    "    print(\"Orders by Quadrant:\")\n",
    "    for quadrant, count in quadrant_summary.items():\n",
    "        pct = (count / len(df)) * 100\n",
    "        print(f\"  {quadrant}: {count:,} orders ({pct:.1f}%)\")\n",
    "    \n",
    "    sample_size = min(1000, len(df))\n",
    "    fig = px.scatter(\n",
    "        df.sample(sample_size),\n",
    "        x='freight_value',\n",
    "        y='sla_compliant',\n",
    "        color='cost_performance_quadrant',\n",
    "        title='Cost vs Performance Matrix',\n",
    "        labels={'freight_value': 'Freight Cost (R$)', 'sla_compliant': 'SLA Compliance'},\n",
    "        category_orders={'cost_performance_quadrant': ['High Cost, High Performance', \n",
    "                                                       'High Cost, Low Performance',\n",
    "                                                       'Low Cost, High Performance',\n",
    "                                                       'Low Cost, Low Performance']},\n",
    "        opacity=0.6\n",
    "    )\n",
    "    \n",
    "    fig.add_hline(y=median_sla, line_dash=\"dash\", line_color=\"gray\", \n",
    "                  annotation_text=f\"Median SLA: {median_sla:.2f}\")\n",
    "    fig.add_vline(x=median_freight, line_dash=\"dash\", line_color=\"gray\", \n",
    "                  annotation_text=f\"Median Freight: R${median_freight:.2f}\")\n",
    "    \n",
    "    fig.update_layout(\n",
    "        xaxis_range=[0, df['freight_value'].quantile(0.95)],\n",
    "        yaxis_range=[0, 1]\n",
    "    )\n",
    "    \n",
    "    fig.show()\n",
    "    fig.write_image(\"presentation/figures/cost_performance_matrix.png\")\n",
    "    print(\"Saved: presentation/figures/cost_performance_matrix.png\")\n",
    "\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba6dc70",
   "metadata": {},
   "source": [
    "## 5.9 Root Cause Analysis (Delays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ce47da",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ROOT CAUSE ANALYSIS (DELAYS)\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Analyze worst performing states\n",
    "if 'customer_state' in df.columns:\n",
    "    state_analysis = df.groupby('customer_state').agg({\n",
    "        'order_id': 'count',\n",
    "        'sla_compliant': 'mean',\n",
    "        'delay_days': 'mean',\n",
    "        'total_delivery_days': 'mean',\n",
    "        'freight_value': 'mean'\n",
    "    }).round(3).reset_index()\n",
    "    \n",
    "    # Top 10 worst states by SLA\n",
    "    worst_states = state_analysis.sort_values('sla_compliant').head(10)\n",
    "    \n",
    "    print(\"Top 10 Worst Performing States by SLA:\")\n",
    "    print(worst_states.to_string(index=False))\n",
    "    \n",
    "    fig = px.bar(worst_states, \n",
    "                 x='customer_state', \n",
    "                 y='sla_compliant',\n",
    "                 title='Top 10 Worst Performing States by SLA',\n",
    "                 labels={'sla_compliant': 'SLA Compliance Rate', 'customer_state': 'State'},\n",
    "                 color='sla_compliant',\n",
    "                 color_continuous_scale='Reds_r')\n",
    "    \n",
    "    fig.show()\n",
    "    fig.write_image(\"presentation/figures/worst_performing_states.png\")\n",
    "    print(\"Saved: presentation/figures/worst_performing_states.png\")\n",
    "    \n",
    "    # Analyze worst states by delay days\n",
    "    worst_delay_states = state_analysis.sort_values('delay_days', ascending=False).head(10)\n",
    "    \n",
    "    print(\"\\nTop 10 Worst States by Average Delay Days:\")\n",
    "    print(worst_delay_states[['customer_state', 'delay_days', 'sla_compliant']].to_string(index=False))\n",
    "\n",
    "# Analyze seasonal patterns\n",
    "print(\"\\nSeasonal Performance Analysis:\")\n",
    "monthly_analysis = df.groupby('purchase_month').agg({\n",
    "    'order_id': 'count',\n",
    "    'sla_compliant': 'mean',\n",
    "    'delay_days': 'mean',\n",
    "    'freight_value': 'mean'\n",
    "}).reset_index()\n",
    "\n",
    "print(monthly_analysis.to_string(index=False))\n",
    "\n",
    "fig = px.line(monthly_analysis, \n",
    "              x='purchase_month', \n",
    "              y=['sla_compliant', 'delay_days'],\n",
    "              title='Monthly Delivery Performance',\n",
    "              labels={'value': 'Metric Value', 'purchase_month': 'Month', 'variable': 'Metric'},\n",
    "              markers=True)\n",
    "\n",
    "fig.update_layout(xaxis=dict(tickmode='linear', dtick=1))\n",
    "fig.show()\n",
    "fig.write_image(\"presentation/figures/monthly_performance_trends.png\")\n",
    "print(\"Saved: presentation/figures/monthly_performance_trends.png\")\n",
    "\n",
    "# Analyze weekday patterns\n",
    "if 'purchase_weekday' in df.columns:\n",
    "    weekday_analysis = df.groupby('purchase_weekday').agg({\n",
    "        'order_id': 'count',\n",
    "        'sla_compliant': 'mean',\n",
    "        'delay_days': 'mean'\n",
    "    }).reset_index()\n",
    "    \n",
    "    # Order weekdays properly\n",
    "    weekday_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "    weekday_analysis['purchase_weekday'] = pd.Categorical(weekday_analysis['purchase_weekday'], \n",
    "                                                          categories=weekday_order, \n",
    "                                                          ordered=True)\n",
    "    weekday_analysis = weekday_analysis.sort_values('purchase_weekday')\n",
    "    \n",
    "    print(\"\\nWeekday Performance Analysis:\")\n",
    "    print(weekday_analysis.to_string(index=False))\n",
    "\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28bbe1ec",
   "metadata": {},
   "source": [
    "## 5.10 Optimization Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016584ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"OPTIMIZATION RECOMMENDATIONS\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Generate data-driven recommendations\n",
    "recommendations = []\n",
    "\n",
    "# 1. Regional optimization\n",
    "if 'region' in df.columns and 'sla_compliant' in df.columns:\n",
    "    regional_sla = df.groupby('region')['sla_compliant'].mean()\n",
    "    worst_region = regional_sla.idxmin()\n",
    "    best_region = regional_sla.idxmax()\n",
    "    \n",
    "    recommendations.append({\n",
    "        'priority': 'High',\n",
    "        'area': 'Regional Logistics',\n",
    "        'recommendation': f'Focus on improving {worst_region} region logistics. Current SLA: {regional_sla[worst_region]:.1%} vs Best region ({best_region}): {regional_sla[best_region]:.1%}',\n",
    "        'expected_impact': 'Improve SLA by 5-10% in worst performing region'\n",
    "    })\n",
    "\n",
    "# 2. Freight optimization\n",
    "if 'freight_value' in df.columns and 'sla_compliant' in df.columns:\n",
    "    freight_categories = df.groupby('freight_category')['sla_compliant'].mean()\n",
    "    optimal_category = freight_categories.idxmax()\n",
    "    \n",
    "    recommendations.append({\n",
    "        'priority': 'Medium',\n",
    "        'area': 'Freight Cost',\n",
    "        'recommendation': f'Optimize freight to {optimal_category} category range for best SLA compliance',\n",
    "        'expected_impact': 'Better cost-performance ratio'\n",
    "    })\n",
    "\n",
    "# 3. Delay impact mitigation\n",
    "if 'delay_days' in df.columns and 'review_score' in df.columns:\n",
    "    severe_delay_threshold = 15\n",
    "    severe_delay_count = len(df[df['delay_days'] > severe_delay_threshold])\n",
    "    severe_delay_pct = severe_delay_count / len(df)\n",
    "    \n",
    "    if severe_delay_pct > 0.05:  # More than 5% severe delays\n",
    "        recommendations.append({\n",
    "            'priority': 'High',\n",
    "            'area': 'Customer Experience',\n",
    "            'recommendation': f'Implement expedited shipping for orders at risk of >{severe_delay_threshold} day delays',\n",
    "            'expected_impact': 'Reduce negative reviews by 15-20%'\n",
    "        })\n",
    "\n",
    "# 4. Seasonal adjustments\n",
    "if 'purchase_month' in df.columns:\n",
    "    monthly_sla = df.groupby('purchase_month')['sla_compliant'].mean()\n",
    "    worst_month = monthly_sla.idxmin()\n",
    "    best_month = monthly_sla.idxmax()\n",
    "    \n",
    "    if monthly_sla[worst_month] < monthly_sla.mean() * 0.9:  # 10% below average\n",
    "        recommendations.append({\n",
    "            'priority': 'Medium',\n",
    "            'area': 'Seasonal Planning',\n",
    "            'recommendation': f'Increase logistics capacity in month {worst_month}',\n",
    "            'expected_impact': 'Smooth seasonal fluctuations'\n",
    "        })\n",
    "\n",
    "# Display recommendations\n",
    "print(\"Data-Driven Recommendations:\")\n",
    "for i, rec in enumerate(recommendations, 1):\n",
    "    print(f\"\\n{i}. [{rec['priority']} Priority] {rec['area']}:\")\n",
    "    print(f\"   Recommendation: {rec['recommendation']}\")\n",
    "    print(f\"   Expected Impact: {rec['expected_impact']}\")\n",
    "\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be235c56",
   "metadata": {},
   "source": [
    "## 6. Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50c704d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"KEY INSIGHTS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Calculate key insights\n",
    "insights = []\n",
    "\n",
    "# 1. Overall performance\n",
    "if 'sla_compliant' in df.columns:\n",
    "    overall_sla = df['sla_compliant'].mean()\n",
    "    insights.append(f\"Overall SLA Compliance: {overall_sla:.1%}\")\n",
    "\n",
    "# 2. Regional performance\n",
    "if 'region' in df.columns and 'sla_compliant' in df.columns:\n",
    "    regional_sla = df.groupby('region')['sla_compliant'].mean()\n",
    "    best_region = regional_sla.idxmax()\n",
    "    worst_region = regional_sla.idxmin()\n",
    "    insights.append(f\"Best performing region: {best_region} ({regional_sla[best_region]:.1%} SLA)\")\n",
    "    insights.append(f\"Worst performing region: {worst_region} ({regional_sla[worst_region]:.1%} SLA)\")\n",
    "\n",
    "# 3. Delay impact\n",
    "if 'delay_days' in df.columns and 'review_score' in df.columns:\n",
    "    corr_delay_review = df['delay_days'].corr(df['review_score'])\n",
    "    insights.append(f\"Delay-Review correlation: {corr_delay_review:.3f} (negative impact confirmed)\")\n",
    "\n",
    "# 4. Cost efficiency\n",
    "if 'freight_value' in df.columns and 'sla_compliant' in df.columns:\n",
    "    corr_freight_sla = df['freight_value'].corr(df['sla_compliant'])\n",
    "    insights.append(f\"Freight-SLA correlation: {corr_freight_sla:.3f}\")\n",
    "\n",
    "# 5. Customer satisfaction\n",
    "if 'review_score' in df.columns:\n",
    "    avg_review = df['review_score'].mean()\n",
    "    positive_pct = (df['review_score'] >= 4).mean() * 100\n",
    "    insights.append(f\"Average review score: {avg_review:.2f}/5.0\")\n",
    "    insights.append(f\"Positive reviews (>=4 stars): {positive_pct:.1f}%\")\n",
    "\n",
    "# Display insights\n",
    "print(\"\\nKey Insights:\")\n",
    "for i, insight in enumerate(insights, 1):\n",
    "    print(f\"{i}. {insight}\")\n",
    "\n",
    "# Executive Summary\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"EXECUTIVE SUMMARY\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "summary = f\"\"\"\n",
    "Delivery Performance Analysis Summary\n",
    "====================================\n",
    "\n",
    "1. PERFORMANCE OVERVIEW\n",
    "   - Total orders analyzed: {len(df):,}\n",
    "   - Overall SLA compliance: {overall_sla:.1%}\n",
    "   - Average delivery time: {df['total_delivery_days'].mean():.1f} days\n",
    "   - Delayed orders: {len(df[df['delay_days'] > 0]):,} ({(len(df[df['delay_days'] > 0])/len(df)*100):.1f}%)\n",
    "\n",
    "2. REGIONAL PERFORMANCE\n",
    "   - Best region: {best_region} ({regional_sla[best_region]:.1%} SLA)\n",
    "   - Worst region: {worst_region} ({regional_sla[worst_region]:.1%} SLA)\n",
    "   - Regional performance varies by {((regional_sla.max() - regional_sla.min())/regional_sla.mean()*100):.0f}%\n",
    "\n",
    "3. CUSTOMER IMPACT\n",
    "   - Each day of delay reduces review score by {abs(review_impact_per_day):.3f} points\n",
    "   - Severe delays (>15 days) have {df[df['delay_days'] > 15]['negative_review'].mean()*100:.0f}% negative reviews\n",
    "   - On-time deliveries have {df[df['delay_days'] <= 0]['positive_review'].mean()*100:.0f}% positive reviews\n",
    "\n",
    "4. COST ANALYSIS\n",
    "   - Average freight cost: R${df['freight_value'].mean():.2f}\n",
    "   - Freight represents {(df['freight_value'].mean()/df['item_price'].mean()*100):.1f}% of item price\n",
    "   - Optimal freight range: R${df[df['freight_category'] == optimal_category]['freight_value'].mean():.2f} avg\n",
    "\n",
    "5. RECOMMENDED ACTIONS\n",
    "   • Priority 1: Improve {worst_region} region logistics\n",
    "   • Priority 2: Implement delay mitigation for high-risk orders\n",
    "   • Priority 3: Optimize freight cost structure\n",
    "\"\"\"\n",
    "\n",
    "print(summary)\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6440fdc1",
   "metadata": {},
   "source": [
    "## 7. Export Graphs and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45389d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"EXPORTING GRAPHS AND DATA\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Export delayed orders report\n",
    "print(\"\\n1. Exporting delayed orders report...\")\n",
    "delayed_orders = df[df['delay_days'] > 0][[\n",
    "    'order_id', 'customer_state', 'region',\n",
    "    'total_delivery_days', 'delay_days', 'delivery_status',\n",
    "    'freight_value', 'review_score'\n",
    "]].sort_values('delay_days', ascending=False)\n",
    "\n",
    "delayed_orders.to_csv('exports/delayed_orders_report.csv', index=False)\n",
    "print(f\"   Exported: exports/delayed_orders_report.csv ({len(delayed_orders):,} records)\")\n",
    "\n",
    "# Export regional performance summary\n",
    "print(\"\\n2. Exporting regional performance summary...\")\n",
    "regional_summary = df.groupby('region').agg({\n",
    "    'order_id': 'count',\n",
    "    'sla_compliant': 'mean',\n",
    "    'delay_days': 'mean',\n",
    "    'total_delivery_days': 'mean',\n",
    "    'freight_value': 'mean',\n",
    "    'review_score': 'mean'\n",
    "}).round(3)\n",
    "\n",
    "regional_summary.to_csv('exports/regional_delivery_summary.csv')\n",
    "print(f\"   Exported: exports/regional_delivery_summary.csv\")\n",
    "\n",
    "# Export improvement priorities\n",
    "print(\"\\n3. Exporting improvement priorities...\")\n",
    "worst_performers = df.groupby('customer_state').agg({\n",
    "    'sla_compliant': 'mean',\n",
    "    'delay_days': 'mean',\n",
    "    'order_id': 'count'\n",
    "}).sort_values('sla_compliant').head(10)\n",
    "\n",
    "worst_performers.to_csv('exports/delivery_improvement_priorities.csv')\n",
    "print(f\"   Exported: exports/delivery_improvement_priorities.csv\")\n",
    "\n",
    "# Export key metrics\n",
    "print(\"\\n4. Exporting key metrics...\")\n",
    "key_metrics = pd.DataFrame({\n",
    "    'Metric': [\n",
    "        'Total Orders',\n",
    "        'SLA Compliance Rate',\n",
    "        'Average Delivery Time (days)',\n",
    "        'Average Delay (days)',\n",
    "        'Delayed Orders Count',\n",
    "        'Delayed Orders Percentage',\n",
    "        'Average Freight Cost (R$)',\n",
    "        'Average Review Score',\n",
    "        'Delay-Review Correlation',\n",
    "        'Freight-SLA Correlation'\n",
    "    ],\n",
    "    'Value': [\n",
    "        len(df),\n",
    "        df['sla_compliant'].mean(),\n",
    "        df['total_delivery_days'].mean(),\n",
    "        df[df['delay_days'] > 0]['delay_days'].mean() if len(df[df['delay_days'] > 0]) > 0 else 0,\n",
    "        len(df[df['delay_days'] > 0]),\n",
    "        len(df[df['delay_days'] > 0]) / len(df) if len(df) > 0 else 0,\n",
    "        df['freight_value'].mean(),\n",
    "        df['review_score'].mean(),\n",
    "        df['delay_days'].corr(df['review_score']),\n",
    "        df['freight_value'].corr(df['sla_compliant'])\n",
    "    ]\n",
    "})\n",
    "\n",
    "key_metrics.to_csv('exports/key_metrics_summary.csv', index=False)\n",
    "print(f\"   Exported: exports/key_metrics_summary.csv\")\n",
    "\n",
    "# Create summary report\n",
    "print(\"\\n5. Creating summary report...\")\n",
    "summary_report = f\"\"\"\n",
    "Delivery Performance Analysis Report\n",
    "===================================\n",
    "\n",
    "Dataset Overview:\n",
    "- Total Orders: {len(df):,}\n",
    "- Time Period: {df['order_purchase_timestamp'].min().date()} to {df['order_purchase_timestamp'].max().date()}\n",
    "- Regions Covered: {df['region'].nunique()}\n",
    "- States Covered: {df['customer_state'].nunique()}\n",
    "\n",
    "Key Metrics:\n",
    "- Overall SLA Compliance: {df['sla_compliant'].mean():.1%}\n",
    "- Average Delivery Time: {df['total_delivery_days'].mean():.1f} days\n",
    "- Average Delay (when delayed): {df[df['delay_days'] > 0]['delay_days'].mean():.1f} days\n",
    "- Delayed Orders: {df[df['delay_days'] > 0].shape[0]:,} ({df[df['delay_days'] > 0].shape[0]/len(df):.1%})\n",
    "- Average Freight Cost: R$ {df['freight_value'].mean():.2f}\n",
    "- Average Review Score: {df['review_score'].mean():.2f}/5.0\n",
    "\n",
    "Top Performing Regions (by SLA):\n",
    "{regional_analysis.sort_values('sla_rate', ascending=False).head(3).to_string()}\n",
    "\n",
    "Bottom Performing Regions (by SLA):\n",
    "{regional_analysis.sort_values('sla_rate').head(3).to_string()}\n",
    "\n",
    "Impact Analysis:\n",
    "- Delay-Review Correlation: {corr_delay_review:.3f}\n",
    "- Review Impact per Delay Day: {review_impact_per_day:.3f} points\n",
    "- SLA Improvement with High Freight: {sla_improvement:.1%} points\n",
    "\n",
    "Recommendations:\n",
    "1. Focus on improving {worst_region} region logistics\n",
    "2. Optimize freight cost for Southeast region\n",
    "3. Implement expedited shipping for high-value orders\n",
    "4. Monitor seasonal patterns in month {worst_month}\n",
    "\"\"\"\n",
    "\n",
    "# Save summary report\n",
    "with open('exports/delivery_analysis_summary.txt', 'w') as f:\n",
    "    f.write(summary_report)\n",
    "\n",
    "print(f\"   Exported: exports/delivery_analysis_summary.txt\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"ANALYSIS COMPLETED SUCCESSFULLY!\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(f\"\\nSummary of exports:\")\n",
    "print(f\"  • Graphs: {len([f for f in os.listdir('presentation/figures') if f.endswith('.png')])} PNG files in presentation/figures/\")\n",
    "print(f\"  • Data: 4 CSV files in exports/\")\n",
    "print(f\"  • Report: 1 TXT file in exports/\")\n",
    "\n",
    "print(f\"\\nTotal visualizations created: 12/12\")\n",
    "print(f\"All required analyses completed: ✓\")\n",
    "print(f\"Data exports successful: ✓\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
