{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "926b077f",
   "metadata": {},
   "source": [
    "# Geographic LTV Analysis\n",
    "Project: QuintoAndar Case Study - Olist E-Commerce Analysis\n",
    "Notebook: 04 - LTV & Geographic Performance\n",
    "Author: Data Science Team\n",
    "Date: 2024-12-10\n",
    "\n",
    "## Objectives:\n",
    "Analyze LTV distribution across Brazilian states\n",
    "\n",
    "Identify high-value and expansion opportunity regions\n",
    "\n",
    "Correlate LTV with operational metrics (delivery, reviews)\n",
    "\n",
    "Map geographic concentration and market penetration\n",
    "\n",
    "Provide actionable recommendations for geographic expansion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57651f9c",
   "metadata": {},
   "source": [
    "## 1. SETUP & IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1b3e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from google.cloud import bigquery\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "# Configurations\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)\n",
    "\n",
    "# Setup BigQuery client\n",
    "PROJECT_ID = \"quintoandar-ecommerce-analysis\"\n",
    "client = bigquery.Client(project=PROJECT_ID)\n",
    "\n",
    "print(\"Setup completed successfully!\")\n",
    "print(f\"Project ID: {PROJECT_ID}\")\n",
    "print(f\"Date: {datetime.now().strftime('%Y-%m-%d')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad435c0",
   "metadata": {},
   "source": [
    "## 2. DATA LOADING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbbaa947",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query 1: Geographic Performance\n",
    "query_geo = f\"\"\"\n",
    "SELECT *\n",
    "FROM `{PROJECT_ID}.olist_marts.mart_geographic_performance`\n",
    "ORDER BY state_code\n",
    "\"\"\"\n",
    "\n",
    "# Query 2: Customer LTV\n",
    "query_ltv = f\"\"\"\n",
    "SELECT \n",
    "    customer_id,\n",
    "    customer_state,\n",
    "    ltv,\n",
    "    total_orders,\n",
    "    total_revenue,\n",
    "    avg_order_value,\n",
    "    customer_lifespan_days,\n",
    "    first_purchase_date,\n",
    "    last_purchase_date\n",
    "FROM `{PROJECT_ID}.olist_marts.mart_customer_ltv`\n",
    "ORDER BY ltv DESC\n",
    "\"\"\"\n",
    "\n",
    "# Load data\n",
    "try:\n",
    "    df_geo = client.query(query_geo).to_dataframe()\n",
    "    df_customer_ltv = client.query(query_ltv).to_dataframe()\n",
    "    print(\"Data loaded successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading data: {e}\")\n",
    "    df_geo = pd.DataFrame()\n",
    "    df_customer_ltv = pd.DataFrame()\n",
    "\n",
    "# Validate data\n",
    "print(\"\\n=== VALIDATION CHECKS ===\")\n",
    "\n",
    "# Check if DataFrames are empty\n",
    "if len(df_geo) > 0:\n",
    "    print(f\"Geographic Performance: {len(df_geo)} rows loaded\")\n",
    "else:\n",
    "    print(\"Geographic Performance DataFrame is empty\")\n",
    "\n",
    "if len(df_customer_ltv) > 0:\n",
    "    print(f\"Customer LTV: {len(df_customer_ltv)} rows loaded\")\n",
    "else:\n",
    "    print(\"Customer LTV DataFrame is empty\")\n",
    "\n",
    "# Check critical columns\n",
    "critical_geo_columns = ['state_code', 'state_name', 'region', 'avg_ltv', 'total_customers', 'total_revenue']\n",
    "missing_geo_cols = [col for col in critical_geo_columns if col not in df_geo.columns]\n",
    "if not missing_geo_cols:\n",
    "    print(\"All critical columns present in geographic data\")\n",
    "else:\n",
    "    print(f\"Missing columns in geographic data: {missing_geo_cols}\")\n",
    "\n",
    "critical_ltv_columns = ['customer_id', 'customer_state', 'ltv']\n",
    "missing_ltv_cols = [col for col in critical_ltv_columns if col not in df_customer_ltv.columns]\n",
    "if not missing_ltv_cols:\n",
    "    print(\"All critical columns present in customer LTV data\")\n",
    "else:\n",
    "    print(f\"Missing columns in customer LTV data: {missing_ltv_cols}\")\n",
    "\n",
    "# Display basic info\n",
    "print(\"\\n=== GEOGRAPHIC DATA SHAPE ===\")\n",
    "print(f\"Shape: {df_geo.shape}\")\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "print(df_geo.head())\n",
    "print(\"\\nData types:\")\n",
    "print(df_geo.dtypes)\n",
    "\n",
    "print(\"\\n=== CUSTOMER LTV DATA SHAPE ===\")\n",
    "print(f\"Shape: {df_customer_ltv.shape}\")\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "print(df_customer_ltv.head())\n",
    "\n",
    "# Statistical summary\n",
    "print(\"\\n=== STATISTICAL SUMMARY (GEOGRAPHIC DATA) ===\")\n",
    "if len(df_geo) > 0 and 'avg_ltv' in df_geo.columns:\n",
    "    print(df_geo.describe())\n",
    "else:\n",
    "    print(\"Cannot display summary - insufficient data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64aad622",
   "metadata": {},
   "source": [
    "## 3. GEOGRAPHIC OVERVIEW (KPIs + CHART)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa88a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== GEOGRAPHIC LTV OVERVIEW ===\\n\")\n",
    "\n",
    "# Calculate KPIs dynamically\n",
    "if len(df_geo) > 0 and 'avg_ltv' in df_geo.columns and 'total_customers' in df_geo.columns:\n",
    "    # KPI 1: Total states\n",
    "    total_states = df_geo['state_code'].nunique()\n",
    "    \n",
    "    # KPI 2: Total customers\n",
    "    total_customers = df_geo['total_customers'].sum()\n",
    "    \n",
    "    # KPI 3: Average LTV Brazil\n",
    "    avg_ltv_brazil = df_geo['avg_ltv'].mean()\n",
    "    \n",
    "    # KPI 4: State with highest LTV\n",
    "    if len(df_geo) > 0:\n",
    "        max_ltv_state = df_geo.loc[df_geo['avg_ltv'].idxmax(), 'state_code']\n",
    "        max_ltv_value = df_geo['avg_ltv'].max()\n",
    "    else:\n",
    "        max_ltv_state = \"N/A\"\n",
    "        max_ltv_value = 0\n",
    "    \n",
    "    # KPI 5: State with lowest LTV\n",
    "    if len(df_geo) > 0:\n",
    "        min_ltv_state = df_geo.loc[df_geo['avg_ltv'].idxmin(), 'state_code']\n",
    "        min_ltv_value = df_geo['avg_ltv'].min()\n",
    "    else:\n",
    "        min_ltv_state = \"N/A\"\n",
    "        min_ltv_value = 0\n",
    "    \n",
    "    # KPI 6: LTV range\n",
    "    ltv_range = max_ltv_value - min_ltv_value\n",
    "    \n",
    "    # KPI 7: Coefficient of variation\n",
    "    ltv_std = df_geo['avg_ltv'].std()\n",
    "    ltv_cv = (ltv_std / avg_ltv_brazil * 100) if avg_ltv_brazil != 0 else 0\n",
    "    \n",
    "    # Display KPIs\n",
    "    print(f\"1. Total states analyzed: {total_states}\")\n",
    "    print(f\"2. Total customers analyzed: {total_customers:,}\")\n",
    "    print(f\"3. Average LTV (Brazil): R$ {avg_ltv_brazil:.2f}\")\n",
    "    print(f\"4. State with highest LTV: {max_ltv_state} (R$ {max_ltv_value:.2f})\")\n",
    "    print(f\"5. State with lowest LTV: {min_ltv_state} (R$ {min_ltv_value:.2f})\")\n",
    "    print(f\"6. LTV range: R$ {ltv_range:.2f}\")\n",
    "    print(f\"7. Coefficient of variation: {ltv_cv:.1f}%\")\n",
    "    \n",
    "    # Calculate top and bottom states\n",
    "    df_sorted = df_geo.sort_values('avg_ltv', ascending=False)\n",
    "    top_3_states = df_sorted.head(3)['state_code'].tolist()\n",
    "    top_3_values = df_sorted.head(3)['avg_ltv'].tolist()\n",
    "    bottom_3_states = df_sorted.tail(3)['state_code'].tolist()\n",
    "    bottom_3_values = df_sorted.tail(3)['avg_ltv'].tolist()\n",
    "    \n",
    "    # Percent difference between best and worst\n",
    "    percent_diff = ((max_ltv_value - min_ltv_value) / min_ltv_value * 100) if min_ltv_value != 0 else 0\n",
    "    \n",
    "    # Regional pattern\n",
    "    region_avg_ltv = df_geo.groupby('region')['avg_ltv'].mean().sort_values(ascending=False)\n",
    "    top_region = region_avg_ltv.index[0] if len(region_avg_ltv) > 0 else \"N/A\"\n",
    "    top_region_value = region_avg_ltv.iloc[0] if len(region_avg_ltv) > 0 else 0\n",
    "    \n",
    "    # Insights\n",
    "    print(\"\\n=== INSIGHTS ===\")\n",
    "    print(f\"1. Top 3 states with highest LTV: {', '.join(top_3_states)} (R$ {top_3_values[0]:.2f}, {top_3_values[1]:.2f}, {top_3_values[2]:.2f})\")\n",
    "    print(f\"2. Bottom 3 states with lowest LTV: {', '.join(bottom_3_states)} (R$ {bottom_3_values[0]:.2f}, {bottom_3_values[1]:.2f}, {bottom_3_values[2]:.2f})\")\n",
    "    print(f\"3. Percent difference between best ({max_ltv_state}) and worst ({min_ltv_state}): {percent_diff:.1f}%\")\n",
    "    print(f\"4. Regional dominance: {top_region} region has highest average LTV (R$ {top_region_value:.2f})\")\n",
    "    print(f\"5. Opportunity: States with LTV below national average: {len(df_geo[df_geo['avg_ltv'] < avg_ltv_brazil])} out of {total_states}\")\n",
    "    \n",
    "    # Visualization 1: Horizontal Bar Chart\n",
    "    fig1 = px.bar(\n",
    "        df_sorted,\n",
    "        y='state_code',\n",
    "        x='avg_ltv',\n",
    "        orientation='h',\n",
    "        color='avg_ltv',\n",
    "        color_continuous_scale='RdYlGn',\n",
    "        title='Average LTV by State (Sorted)',\n",
    "        labels={'avg_ltv': 'Average LTV (R$)', 'state_code': 'State'},\n",
    "        text='avg_ltv'\n",
    "    )\n",
    "    \n",
    "    fig1.update_traces(\n",
    "        texttemplate='R$ %{text:.0f}',\n",
    "        textposition='outside'\n",
    "    )\n",
    "    \n",
    "    fig1.update_layout(\n",
    "        height=800,\n",
    "        yaxis={'categoryorder': 'total ascending'},\n",
    "        coloraxis_showscale=True,\n",
    "        xaxis_title=\"Average LTV (R$)\",\n",
    "        yaxis_title=\"State\"\n",
    "    )\n",
    "    \n",
    "    fig1.show()\n",
    "    \n",
    "else:\n",
    "    print(\"Insufficient data for analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7128dba",
   "metadata": {},
   "source": [
    "\n",
    "## 4. BRAZIL MAP - LTV HEATMAP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3640b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== BRAZIL HEATMAP - LTV DISTRIBUTION ===\\n\")\n",
    "\n",
    "if len(df_geo) > 0 and 'state_code' in df_geo.columns and 'avg_ltv' in df_geo.columns:\n",
    "    # Check if we have all 27 states (26 states + DF)\n",
    "    states_present = len(df_geo)\n",
    "    print(f\"States in data: {states_present} out of 27\")\n",
    "    \n",
    "    if states_present < 27:\n",
    "        print(f\"Note: Missing {27 - states_present} state(s)\")\n",
    "    \n",
    "    # Visualization 2: Choropleth Map\n",
    "    fig2 = px.choropleth(\n",
    "        df_geo,\n",
    "        locations='state_code',\n",
    "        locationmode='ISO-3',\n",
    "        color='avg_ltv',\n",
    "        hover_data=['state_name', 'total_customers', 'total_revenue', 'avg_delivery_days', 'avg_review_score'],\n",
    "        color_continuous_scale='RdYlGn',\n",
    "        title='Brazil LTV Heatmap by State',\n",
    "        labels={'avg_ltv': 'Average LTV (R$)'},\n",
    "        scope='south america'\n",
    "    )\n",
    "    \n",
    "    fig2.update_layout(\n",
    "        geo=dict(\n",
    "            showframe=False,\n",
    "            showcoastlines=False,\n",
    "            projection_type='mercator',\n",
    "            center={'lat': -14, 'lon': -55},\n",
    "            lataxis_range=[-35, 5],\n",
    "            lonaxis_range=[-75, -30]\n",
    "        ),\n",
    "        height=600,\n",
    "        coloraxis_colorbar=dict(\n",
    "            title=\"LTV (R$)\",\n",
    "            thickness=20,\n",
    "            len=0.75\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    fig2.show()\n",
    "    \n",
    "    # Insights\n",
    "    print(\"\\n=== INSIGHTS FROM HEATMAP ===\")\n",
    "    \n",
    "    # Check geographic concentration\n",
    "    southeast_states = ['SP', 'RJ', 'MG', 'ES']\n",
    "    southeast_data = df_geo[df_geo['state_code'].isin(southeast_states)]\n",
    "    \n",
    "    if len(southeast_data) > 0:\n",
    "        southeast_avg_ltv = southeast_data['avg_ltv'].mean()\n",
    "        southeast_revenue_pct = (southeast_data['total_revenue'].sum() / df_geo['total_revenue'].sum() * 100) if df_geo['total_revenue'].sum() != 0 else 0\n",
    "        \n",
    "        print(f\"1. Southeast region (SP, RJ, MG, ES) represents {southeast_revenue_pct:.1f}% of total revenue\")\n",
    "        print(f\"2. Average LTV in Southeast: R$ {southeast_avg_ltv:.2f}\")\n",
    "    \n",
    "    # Identify states with low/zero penetration\n",
    "    low_customer_states = df_geo[df_geo['total_customers'] < df_geo['total_customers'].median()]\n",
    "    if len(low_customer_states) > 0:\n",
    "        print(f\"3. Low penetration states: {', '.join(low_customer_states['state_code'].tolist())}\")\n",
    "    \n",
    "    # Identify clusters\n",
    "    high_ltv_states = df_geo[df_geo['avg_ltv'] > df_geo['avg_ltv'].quantile(0.75)]\n",
    "    low_ltv_states = df_geo[df_geo['avg_ltv'] < df_geo['avg_ltv'].quantile(0.25)]\n",
    "    \n",
    "    if len(high_ltv_states) > 0:\n",
    "        print(f\"4. High LTV cluster: {', '.join(high_ltv_states['state_code'].tolist())}\")\n",
    "    \n",
    "    if len(low_ltv_states) > 0:\n",
    "        print(f\"5. Low LTV cluster: {', '.join(low_ltv_states['state_code'].tolist())}\")\n",
    "        \n",
    "else:\n",
    "    print(\"Insufficient data for heatmap\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81233306",
   "metadata": {},
   "source": [
    "## 5. SCATTER PLOT: VOLUME VS LTV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b822bf5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== VOLUME VS LTV ANALYSIS ===\\n\")\n",
    "\n",
    "if len(df_geo) > 0 and 'total_customers' in df_geo.columns and 'avg_ltv' in df_geo.columns:\n",
    "    # Calculate correlation\n",
    "    correlation = df_geo['total_customers'].corr(df_geo['avg_ltv'])\n",
    "    print(f\"Pearson correlation between volume (customers) and LTV: {correlation:.3f}\")\n",
    "    \n",
    "    # Identify outliers\n",
    "    z_score_ltv = (df_geo['avg_ltv'] - df_geo['avg_ltv'].mean()) / df_geo['avg_ltv'].std()\n",
    "    z_score_customers = (df_geo['total_customers'] - df_geo['total_customers'].mean()) / df_geo['total_customers'].std()\n",
    "    \n",
    "    outliers = df_geo[(abs(z_score_ltv) > 2) | (abs(z_score_customers) > 2)]\n",
    "    \n",
    "    if len(outliers) > 0:\n",
    "        print(f\"Outlier states detected: {', '.join(outliers['state_code'].tolist())}\")\n",
    "    \n",
    "    # Calculate quadrant thresholds\n",
    "    median_customers = df_geo['total_customers'].median()\n",
    "    median_ltv = df_geo['avg_ltv'].median()\n",
    "    \n",
    "    # Classify states by quadrant\n",
    "    df_geo['quadrant'] = 'Unknown'\n",
    "    \n",
    "    for idx, row in df_geo.iterrows():\n",
    "        if row['total_customers'] >= median_customers and row['avg_ltv'] >= median_ltv:\n",
    "            df_geo.at[idx, 'quadrant'] = 'High Volume, High LTV (Ideal)'\n",
    "        elif row['total_customers'] >= median_customers and row['avg_ltv'] < median_ltv:\n",
    "            df_geo.at[idx, 'quadrant'] = 'High Volume, Low LTV (Problem)'\n",
    "        elif row['total_customers'] < median_customers and row['avg_ltv'] >= median_ltv:\n",
    "            df_geo.at[idx, 'quadrant'] = 'Low Volume, High LTV (Opportunity)'\n",
    "        else:\n",
    "            df_geo.at[idx, 'quadrant'] = 'Low Volume, Low LTV (Challenge)'\n",
    "    \n",
    "    # Count states in each quadrant\n",
    "    quadrant_counts = df_geo['quadrant'].value_counts()\n",
    "    print(\"\\nQuadrant Distribution:\")\n",
    "    for quadrant, count in quadrant_counts.items():\n",
    "        print(f\"  {quadrant}: {count} states\")\n",
    "    \n",
    "    # Calculate potential market size\n",
    "    if 'total_revenue' in df_geo.columns:\n",
    "        opportunity_quadrant = df_geo[df_geo['quadrant'] == 'Low Volume, High LTV (Opportunity)']\n",
    "        if len(opportunity_quadrant) > 0:\n",
    "            opportunity_revenue = opportunity_quadrant['total_revenue'].sum()\n",
    "            total_revenue = df_geo['total_revenue'].sum()\n",
    "            opportunity_pct = (opportunity_revenue / total_revenue * 100) if total_revenue != 0 else 0\n",
    "            print(f\"\\nOpportunity Quadrant Revenue: R$ {opportunity_revenue:.0f} ({opportunity_pct:.1f}% of total)\")\n",
    "    \n",
    "    # Visualization 3: Scatter Plot\n",
    "    fig3 = px.scatter(\n",
    "        df_geo,\n",
    "        x='total_customers',\n",
    "        y='avg_ltv',\n",
    "        size='total_revenue' if 'total_revenue' in df_geo.columns else None,\n",
    "        color='region',\n",
    "        hover_name='state_code',\n",
    "        hover_data=['state_name', 'total_revenue', 'avg_order_value'],\n",
    "        title='Customer Volume vs LTV by State',\n",
    "        labels={\n",
    "            'total_customers': 'Total Customers',\n",
    "            'avg_ltv': 'Average LTV (R$)',\n",
    "            'region': 'Region',\n",
    "            'total_revenue': 'Total Revenue'\n",
    "        },\n",
    "        size_max=50\n",
    "    )\n",
    "    \n",
    "    # Add quadrant lines\n",
    "    fig3.add_shape(\n",
    "        type=\"line\",\n",
    "        x0=median_customers,\n",
    "        y0=df_geo['avg_ltv'].min(),\n",
    "        x1=median_customers,\n",
    "        y1=df_geo['avg_ltv'].max(),\n",
    "        line=dict(color=\"gray\", width=1, dash=\"dash\")\n",
    "    )\n",
    "    \n",
    "    fig3.add_shape(\n",
    "        type=\"line\",\n",
    "        x0=df_geo['total_customers'].min(),\n",
    "        y0=median_ltv,\n",
    "        x1=df_geo['total_customers'].max(),\n",
    "        y1=median_ltv,\n",
    "        line=dict(color=\"gray\", width=1, dash=\"dash\")\n",
    "    )\n",
    "    \n",
    "    # Add quadrant annotations\n",
    "    fig3.add_annotation(\n",
    "        x=df_geo['total_customers'].max() * 0.75,\n",
    "        y=df_geo['avg_ltv'].max() * 0.75,\n",
    "        text=\"High Volume<br>High LTV\",\n",
    "        showarrow=False,\n",
    "        font=dict(size=10)\n",
    "    )\n",
    "    \n",
    "    fig3.add_annotation(\n",
    "        x=df_geo['total_customers'].max() * 0.75,\n",
    "        y=df_geo['avg_ltv'].min() * 1.25,\n",
    "        text=\"High Volume<br>Low LTV\",\n",
    "        showarrow=False,\n",
    "        font=dict(size=10)\n",
    "    )\n",
    "    \n",
    "    fig3.add_annotation(\n",
    "        x=df_geo['total_customers'].min() * 1.25,\n",
    "        y=df_geo['avg_ltv'].max() * 0.75,\n",
    "        text=\"Low Volume<br>High LTV\",\n",
    "        showarrow=False,\n",
    "        font=dict(size=10)\n",
    "    )\n",
    "    \n",
    "    fig3.add_annotation(\n",
    "        x=df_geo['total_customers'].min() * 1.25,\n",
    "        y=df_geo['avg_ltv'].min() * 1.25,\n",
    "        text=\"Low Volume<br>Low LTV\",\n",
    "        showarrow=False,\n",
    "        font=dict(size=10)\n",
    "    )\n",
    "    \n",
    "    fig3.update_layout(\n",
    "        height=600,\n",
    "        xaxis_title=\"Total Customers\",\n",
    "        yaxis_title=\"Average LTV (R$)\"\n",
    "    )\n",
    "    \n",
    "    fig3.show()\n",
    "    \n",
    "    # Detailed quadrant analysis\n",
    "    print(\"\\n=== QUADRANT ANALYSIS ===\")\n",
    "    \n",
    "    for quadrant in ['High Volume, High LTV (Ideal)', 'High Volume, Low LTV (Problem)',\n",
    "                     'Low Volume, High LTV (Opportunity)', 'Low Volume, Low LTV (Challenge)']:\n",
    "        quadrant_states = df_geo[df_geo['quadrant'] == quadrant]\n",
    "        if len(quadrant_states) > 0:\n",
    "            states_list = ', '.join(quadrant_states['state_code'].tolist())\n",
    "            avg_ltv_val = quadrant_states['avg_ltv'].mean()\n",
    "            avg_customers = quadrant_states['total_customers'].mean()\n",
    "            \n",
    "            print(f\"\\n{quadrant}:\")\n",
    "            print(f\"  States: {states_list}\")\n",
    "            print(f\"  Avg LTV: R$ {avg_ltv_val:.2f}\")\n",
    "            print(f\"  Avg Customers: {avg_customers:.0f}\")\n",
    "    \n",
    "    # Insights\n",
    "    print(\"\\n=== INSIGHTS ===\")\n",
    "    print(f\"1. Correlation between volume and LTV is {correlation:.3f} ({'positive' if correlation > 0 else 'negative'} relationship)\")\n",
    "    \n",
    "    ideal_states = df_geo[df_geo['quadrant'] == 'High Volume, High LTV (Ideal)']\n",
    "    if len(ideal_states) > 0:\n",
    "        print(f\"2. Ideal states (high volume, high LTV): {', '.join(ideal_states['state_code'].tolist())}\")\n",
    "    \n",
    "    opportunity_states = df_geo[df_geo['quadrant'] == 'Low Volume, High LTV (Opportunity)']\n",
    "    if len(opportunity_states) > 0:\n",
    "        print(f\"3. Top expansion opportunities: {', '.join(opportunity_states['state_code'].tolist())}\")\n",
    "        \n",
    "else:\n",
    "    print(\"Insufficient data for scatter plot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "823690d5",
   "metadata": {},
   "source": [
    "## 6. STATE RANKING (TOP 10 + BOTTOM 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9213140",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== STATE RANKING ANALYSIS ===\\n\")\n",
    "\n",
    "if len(df_geo) > 0 and 'total_revenue' in df_geo.columns:\n",
    "    # Sort by LTV for ranking\n",
    "    df_sorted_ltv = df_geo.sort_values('avg_ltv', ascending=False).reset_index(drop=True)\n",
    "    df_sorted_ltv.index = df_sorted_ltv.index + 1\n",
    "    \n",
    "    # Calculate revenue contribution\n",
    "    total_revenue = df_geo['total_revenue'].sum()\n",
    "    df_geo['revenue_contribution_pct'] = (df_geo['total_revenue'] / total_revenue * 100) if total_revenue != 0 else 0\n",
    "    \n",
    "    # Sort by revenue for concentration analysis\n",
    "    df_sorted_revenue = df_geo.sort_values('total_revenue', ascending=False).reset_index(drop=True)\n",
    "    \n",
    "    # Calculate cumulative revenue percentage\n",
    "    df_sorted_revenue['cumulative_revenue'] = df_sorted_revenue['total_revenue'].cumsum()\n",
    "    df_sorted_revenue['cumulative_pct'] = (df_sorted_revenue['cumulative_revenue'] / total_revenue * 100) if total_revenue != 0 else 0\n",
    "    \n",
    "    # Table 1: Top 10 States by LTV\n",
    "    print(\"TOP 10 STATES BY LTV:\")\n",
    "    print(\"=\" * 80)\n",
    "    top_10_ltv = df_sorted_ltv.head(10)[['state_code', 'state_name', 'avg_ltv', 'total_customers', 'total_revenue', 'avg_order_value']]\n",
    "    top_10_ltv['revenue_contribution_pct'] = (top_10_ltv['total_revenue'] / total_revenue * 100) if total_revenue != 0 else 0\n",
    "    print(top_10_ltv.round(2))\n",
    "    \n",
    "    # Table 2: Bottom 10 States by LTV\n",
    "    print(\"\\n\\nBOTTOM 10 STATES BY LTV:\")\n",
    "    print(\"=\" * 80)\n",
    "    bottom_10_ltv = df_sorted_ltv.tail(10)[['state_code', 'state_name', 'avg_ltv', 'total_customers', 'total_revenue', 'avg_order_value']]\n",
    "    bottom_10_ltv['revenue_contribution_pct'] = (bottom_10_ltv['total_revenue'] / total_revenue * 100) if total_revenue != 0 else 0\n",
    "    print(bottom_10_ltv.round(2))\n",
    "    \n",
    "    # Concentration metrics\n",
    "    print(\"\\n=== CONCENTRATION ANALYSIS ===\")\n",
    "    \n",
    "    # Top 5 states revenue percentage\n",
    "    top_5_revenue = df_sorted_revenue.head(5)['total_revenue'].sum()\n",
    "    top_5_pct = (top_5_revenue / total_revenue * 100) if total_revenue != 0 else 0\n",
    "    print(f\"Top 5 states account for {top_5_pct:.1f}% of total revenue\")\n",
    "    \n",
    "    # Top 10 states revenue percentage\n",
    "    top_10_revenue = df_sorted_revenue.head(10)['total_revenue'].sum()\n",
    "    top_10_pct = (top_10_revenue / total_revenue * 100) if total_revenue != 0 else 0\n",
    "    print(f\"Top 10 states account for {top_10_pct:.1f}% of total revenue\")\n",
    "    \n",
    "    # Gini index calculation (simplified)\n",
    "    sorted_revenue = np.sort(df_geo['total_revenue'])\n",
    "    n = len(sorted_revenue)\n",
    "    cumulative_revenue = np.cumsum(sorted_revenue)\n",
    "    \n",
    "    if total_revenue > 0 and n > 0:\n",
    "        # Calculate Lorenz curve values\n",
    "        lorenz = cumulative_revenue / total_revenue\n",
    "        # Calculate Gini index (area between line of equality and Lorenz curve)\n",
    "        gini = 1 - 2 * np.trapz(lorenz, dx=1/n)\n",
    "        print(f\"Gini Index (revenue concentration): {gini:.3f}\")\n",
    "    \n",
    "    # Number of states to reach 80% revenue (Pareto)\n",
    "    states_to_80 = len(df_sorted_revenue[df_sorted_revenue['cumulative_pct'] <= 80])\n",
    "    print(f\"Number of states to reach 80% of revenue: {states_to_80}\")\n",
    "    \n",
    "    # Visualization 4: Pareto Chart\n",
    "    fig4 = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
    "    \n",
    "    # Bar chart for revenue\n",
    "    fig4.add_trace(\n",
    "        go.Bar(\n",
    "            x=df_sorted_revenue['state_code'],\n",
    "            y=df_sorted_revenue['total_revenue'],\n",
    "            name=\"Revenue\",\n",
    "            marker_color='blue'\n",
    "        ),\n",
    "        secondary_y=False\n",
    "    )\n",
    "    \n",
    "    # Line chart for cumulative percentage\n",
    "    fig4.add_trace(\n",
    "        go.Scatter(\n",
    "            x=df_sorted_revenue['state_code'],\n",
    "            y=df_sorted_revenue['cumulative_pct'],\n",
    "            name=\"Cumulative %\",\n",
    "            mode='lines+markers',\n",
    "            line=dict(color='red', width=2)\n",
    "        ),\n",
    "        secondary_y=True\n",
    "    )\n",
    "    \n",
    "    # Add 80% line\n",
    "    fig4.add_hline(\n",
    "        y=80,\n",
    "        line_dash=\"dash\",\n",
    "        line_color=\"green\",\n",
    "        annotation_text=\"80% Threshold\",\n",
    "        annotation_position=\"bottom right\",\n",
    "        secondary_y=True\n",
    "    )\n",
    "    \n",
    "    fig4.update_layout(\n",
    "        title=\"Pareto Chart: Revenue Concentration by State\",\n",
    "        xaxis_title=\"State (sorted by revenue)\",\n",
    "        height=600,\n",
    "        showlegend=True\n",
    "    )\n",
    "    \n",
    "    fig4.update_yaxes(\n",
    "        title_text=\"Revenue (R$)\",\n",
    "        secondary_y=False\n",
    "    )\n",
    "    \n",
    "    fig4.update_yaxes(\n",
    "        title_text=\"Cumulative Percentage (%)\",\n",
    "        range=[0, 100],\n",
    "        secondary_y=True\n",
    "    )\n",
    "    \n",
    "    fig4.show()\n",
    "    \n",
    "    # Insights\n",
    "    print(\"\\n=== INSIGHTS ===\")\n",
    "    print(f\"1. Market concentration: Top {states_to_80} states generate 80% of total revenue\")\n",
    "    print(f\"2. Dependence risk: Top 5 states account for {top_5_pct:.1f}% of revenue\")\n",
    "    \n",
    "    # Identify underutilized states\n",
    "    avg_revenue_per_state = total_revenue / len(df_geo)\n",
    "    underutilized = df_geo[df_geo['total_revenue'] < avg_revenue_per_state * 0.5]\n",
    "    \n",
    "    if len(underutilized) > 0:\n",
    "        print(f\"3. Underutilized states (revenue < 50% of average): {', '.join(underutilized['state_code'].tolist())}\")\n",
    "    \n",
    "    # Diversification opportunity\n",
    "    bottom_50_states = len(df_geo) // 2\n",
    "    bottom_50_revenue = df_sorted_revenue.tail(bottom_50_states)['total_revenue'].sum()\n",
    "    bottom_50_pct = (bottom_50_revenue / total_revenue * 100) if total_revenue != 0 else 0\n",
    "    \n",
    "    print(f\"4. Bottom {bottom_50_states} states contribute only {bottom_50_pct:.1f}% of revenue - high diversification opportunity\")\n",
    "        \n",
    "else:\n",
    "    print(\"Insufficient data for ranking analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d14a92",
   "metadata": {},
   "source": [
    "## 7. ANALYSIS BY BRAZILIAN REGION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71aaa2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== REGIONAL ANALYSIS ===\\n\")\n",
    "\n",
    "if len(df_geo) > 0 and 'region' in df_geo.columns:\n",
    "    # Aggregate by region\n",
    "    region_analysis = df_geo.groupby('region').agg({\n",
    "        'total_customers': 'sum',\n",
    "        'total_revenue': 'sum',\n",
    "        'avg_ltv': 'mean',\n",
    "        'avg_order_value': 'mean',\n",
    "        'avg_delivery_days': 'mean',\n",
    "        'avg_review_score': 'mean',\n",
    "        'state_code': 'count'\n",
    "    }).reset_index()\n",
    "    \n",
    "    region_analysis = region_analysis.rename(columns={'state_code': 'state_count'})\n",
    "    \n",
    "    # Calculate additional metrics\n",
    "    total_customers_all = region_analysis['total_customers'].sum()\n",
    "    total_revenue_all = region_analysis['total_revenue'].sum()\n",
    "    \n",
    "    region_analysis['customer_share_pct'] = (region_analysis['total_customers'] / total_customers_all * 100) if total_customers_all != 0 else 0\n",
    "    region_analysis['revenue_share_pct'] = (region_analysis['total_revenue'] / total_revenue_all * 100) if total_revenue_all != 0 else 0\n",
    "    region_analysis['revenue_per_customer'] = (region_analysis['total_revenue'] / region_analysis['total_customers']) if region_analysis['total_customers'] != 0 else 0\n",
    "    \n",
    "    print(\"REGIONAL PERFORMANCE METRICS:\")\n",
    "    print(\"=\" * 100)\n",
    "    print(region_analysis.round(2))\n",
    "    \n",
    "    # Find best performing regions\n",
    "    print(\"\\n=== REGIONAL LEADERS ===\")\n",
    "    \n",
    "    if len(region_analysis) > 0:\n",
    "        # Region with highest LTV\n",
    "        region_highest_ltv = region_analysis.loc[region_analysis['avg_ltv'].idxmax(), 'region']\n",
    "        highest_ltv_value = region_analysis['avg_ltv'].max()\n",
    "        print(f\"Highest LTV region: {region_highest_ltv} (R$ {highest_ltv_value:.2f})\")\n",
    "        \n",
    "        # Region with most customers\n",
    "        region_most_customers = region_analysis.loc[region_analysis['total_customers'].idxmax(), 'region']\n",
    "        most_customers_value = region_analysis['total_customers'].max()\n",
    "        print(f\"Highest volume region: {region_most_customers} ({most_customers_value:,} customers)\")\n",
    "        \n",
    "        # Region with highest AOV\n",
    "        region_highest_aov = region_analysis.loc[region_analysis['avg_order_value'].idxmax(), 'region']\n",
    "        highest_aov_value = region_analysis['avg_order_value'].max()\n",
    "        print(f\"Highest AOV region: {region_highest_aov} (R$ {highest_aov_value:.2f})\")\n",
    "        \n",
    "        # Region with best delivery\n",
    "        region_best_delivery = region_analysis.loc[region_analysis['avg_delivery_days'].idxmin(), 'region']\n",
    "        best_delivery_value = region_analysis['avg_delivery_days'].min()\n",
    "        print(f\"Fastest delivery region: {region_best_delivery} ({best_delivery_value:.1f} days)\")\n",
    "        \n",
    "        # Region with best reviews\n",
    "        region_best_reviews = region_analysis.loc[region_analysis['avg_review_score'].idxmax(), 'region']\n",
    "        best_reviews_value = region_analysis['avg_review_score'].max()\n",
    "        print(f\"Highest review score region: {region_best_reviews} ({best_reviews_value:.2f})\")\n",
    "    \n",
    "    # Visualization 5: Grouped Bar Chart\n",
    "    fig5 = make_subplots(\n",
    "        rows=2, cols=2,\n",
    "        subplot_titles=('Total Customers', 'Average LTV', 'Average Order Value', 'Revenue per Customer'),\n",
    "        vertical_spacing=0.15,\n",
    "        horizontal_spacing=0.15\n",
    "    )\n",
    "    \n",
    "    # Chart 1: Total Customers\n",
    "    fig5.add_trace(\n",
    "        go.Bar(\n",
    "            x=region_analysis['region'],\n",
    "            y=region_analysis['total_customers'],\n",
    "            name='Customers',\n",
    "            marker_color='skyblue'\n",
    "        ),\n",
    "        row=1, col=1\n",
    "    )\n",
    "    \n",
    "    # Chart 2: Average LTV\n",
    "    fig5.add_trace(\n",
    "        go.Bar(\n",
    "            x=region_analysis['region'],\n",
    "            y=region_analysis['avg_ltv'],\n",
    "            name='LTV',\n",
    "            marker_color='lightgreen'\n",
    "        ),\n",
    "        row=1, col=2\n",
    "    )\n",
    "    \n",
    "    # Chart 3: Average Order Value\n",
    "    fig5.add_trace(\n",
    "        go.Bar(\n",
    "            x=region_analysis['region'],\n",
    "            y=region_analysis['avg_order_value'],\n",
    "            name='AOV',\n",
    "            marker_color='salmon'\n",
    "        ),\n",
    "        row=2, col=1\n",
    "    )\n",
    "    \n",
    "    # Chart 4: Revenue per Customer\n",
    "    fig5.add_trace(\n",
    "        go.Bar(\n",
    "            x=region_analysis['region'],\n",
    "            y=region_analysis['revenue_per_customer'],\n",
    "            name='Revenue/Customer',\n",
    "            marker_color='gold'\n",
    "        ),\n",
    "        row=2, col=2\n",
    "    )\n",
    "    \n",
    "    fig5.update_layout(\n",
    "        title_text='Regional Performance Metrics',\n",
    "        height=700,\n",
    "        showlegend=False\n",
    "    )\n",
    "    \n",
    "    # Update axes labels\n",
    "    fig5.update_yaxes(title_text=\"Count\", row=1, col=1)\n",
    "    fig5.update_yaxes(title_text=\"R$\", row=1, col=2)\n",
    "    fig5.update_yaxes(title_text=\"R$\", row=2, col=1)\n",
    "    fig5.update_yaxes(title_text=\"R$\", row=2, col=2)\n",
    "    \n",
    "    fig5.show()\n",
    "    \n",
    "    # Insights\n",
    "    print(\"\\n=== INSIGHTS ===\")\n",
    "    \n",
    "    # Most profitable region\n",
    "    region_highest_revenue = region_analysis.loc[region_analysis['total_revenue'].idxmax(), 'region']\n",
    "    highest_revenue_value = region_analysis['total_revenue'].max()\n",
    "    highest_revenue_pct = region_analysis.loc[region_analysis['total_revenue'].idxmax(), 'revenue_share_pct']\n",
    "    print(f\"1. Most profitable region: {region_highest_revenue} (R$ {highest_revenue_value:,.0f}, {highest_revenue_pct:.1f}% of total)\")\n",
    "    \n",
    "    # Growth potential regions\n",
    "    region_lowest_penetration = region_analysis.loc[region_analysis['customer_share_pct'].idxmin(), 'region']\n",
    "    lowest_penetration_pct = region_analysis['customer_share_pct'].min()\n",
    "    print(f\"2. Lowest penetration region: {region_lowest_penetration} ({lowest_penetration_pct:.1f}% of customers)\")\n",
    "    \n",
    "    # Operational challenges\n",
    "    region_slowest_delivery = region_analysis.loc[region_analysis['avg_delivery_days'].idxmax(), 'region']\n",
    "    slowest_delivery_value = region_analysis['avg_delivery_days'].max()\n",
    "    print(f\"3. Operational challenge: {region_slowest_delivery} has slowest delivery ({slowest_delivery_value:.1f} days)\")\n",
    "    \n",
    "    # Cultural/behavioral differences\n",
    "    region_lowest_reviews = region_analysis.loc[region_analysis['avg_review_score'].idxmin(), 'region']\n",
    "    lowest_reviews_value = region_analysis['avg_review_score'].min()\n",
    "    print(f\"4. Customer satisfaction challenge: {region_lowest_reviews} has lowest review score ({lowest_reviews_value:.2f})\")\n",
    "    \n",
    "    # Investment prioritization\n",
    "    print(\"5. Investment priority (based on LTV growth potential):\")\n",
    "    region_analysis_sorted = region_analysis.sort_values('avg_ltv', ascending=False)\n",
    "    for idx, row in region_analysis_sorted.iterrows():\n",
    "        print(f\"   {row['region']}: R$ {row['avg_ltv']:.2f} LTV, {row['customer_share_pct']:.1f}% market share\")\n",
    "        \n",
    "else:\n",
    "    print(\"Insufficient data for regional analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3cd0304",
   "metadata": {},
   "source": [
    "## 8. CORRELATIONS: LTV VS OPERATIONAL METRICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbcab366",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== LTV CORRELATION ANALYSIS ===\\n\")\n",
    "\n",
    "if len(df_geo) > 0:\n",
    "    # Select columns for correlation analysis\n",
    "    correlation_columns = ['avg_ltv', 'total_customers', 'avg_order_value', \n",
    "                          'avg_delivery_days', 'avg_review_score', 'total_orders']\n",
    "    \n",
    "    # Check which columns exist in the dataframe\n",
    "    available_columns = [col for col in correlation_columns if col in df_geo.columns]\n",
    "    \n",
    "    if len(available_columns) >= 3:  # Need at least 3 columns for meaningful correlation\n",
    "        # Create correlation matrix\n",
    "        corr_matrix = df_geo[available_columns].corr()\n",
    "        \n",
    "        print(\"CORRELATION MATRIX:\")\n",
    "        print(\"=\" * 60)\n",
    "        print(corr_matrix.round(3))\n",
    "        \n",
    "        # Visualization 6: Heatmap\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        sns.heatmap(corr_matrix, \n",
    "                   annot=True, \n",
    "                   cmap='coolwarm', \n",
    "                   center=0,\n",
    "                   square=True,\n",
    "                   linewidths=1,\n",
    "                   cbar_kws={\"shrink\": 0.8})\n",
    "        plt.title('Correlation Matrix: LTV vs Operational Metrics')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Specific correlation analyses\n",
    "        print(\"\\n=== SPECIFIC CORRELATION ANALYSES ===\")\n",
    "        \n",
    "        # A) LTV vs Delivery Time\n",
    "        if 'avg_ltv' in df_geo.columns and 'avg_delivery_days' in df_geo.columns:\n",
    "            corr_ltv_delivery = df_geo['avg_ltv'].corr(df_geo['avg_delivery_days'])\n",
    "            print(f\"\\nA) LTV vs Delivery Time Correlation: {corr_ltv_delivery:.3f}\")\n",
    "            \n",
    "            fig6a = px.scatter(\n",
    "                df_geo,\n",
    "                x='avg_delivery_days',\n",
    "                y='avg_ltv',\n",
    "                trendline='ols',\n",
    "                hover_name='state_code',\n",
    "                hover_data=['state_name', 'total_customers'],\n",
    "                title='LTV vs Delivery Time',\n",
    "                labels={'avg_delivery_days': 'Average Delivery Days', 'avg_ltv': 'Average LTV (R$)'}\n",
    "            )\n",
    "            \n",
    "            fig6a.update_layout(height=500)\n",
    "            fig6a.show()\n",
    "            \n",
    "            # Get regression results\n",
    "            from sklearn.linear_model import LinearRegression\n",
    "            X = df_geo[['avg_delivery_days']].dropna()\n",
    "            y = df_geo.loc[X.index, 'avg_ltv']\n",
    "            \n",
    "            if len(X) > 0 and len(y) > 0:\n",
    "                model = LinearRegression()\n",
    "                model.fit(X, y)\n",
    "                slope = model.coef_[0]\n",
    "                print(f\"   Impact: Each additional delivery day changes LTV by R$ {slope:.2f}\")\n",
    "        \n",
    "        # B) LTV vs Review Score\n",
    "        if 'avg_ltv' in df_geo.columns and 'avg_review_score' in df_geo.columns:\n",
    "            corr_ltv_reviews = df_geo['avg_ltv'].corr(df_geo['avg_review_score'])\n",
    "            print(f\"\\nB) LTV vs Review Score Correlation: {corr_ltv_reviews:.3f}\")\n",
    "            \n",
    "            fig6b = px.scatter(\n",
    "                df_geo,\n",
    "                x='avg_review_score',\n",
    "                y='avg_ltv',\n",
    "                trendline='ols',\n",
    "                hover_name='state_code',\n",
    "                hover_data=['state_name', 'total_customers'],\n",
    "                title='LTV vs Review Score',\n",
    "                labels={'avg_review_score': 'Average Review Score', 'avg_ltv': 'Average LTV (R$)'}\n",
    "            )\n",
    "            \n",
    "            fig6b.update_layout(height=500)\n",
    "            fig6b.show()\n",
    "            \n",
    "            # Get regression results\n",
    "            X = df_geo[['avg_review_score']].dropna()\n",
    "            y = df_geo.loc[X.index, 'avg_ltv']\n",
    "            \n",
    "            if len(X) > 0 and len(y) > 0:\n",
    "                model = LinearRegression()\n",
    "                model.fit(X, y)\n",
    "                slope = model.coef_[0]\n",
    "                print(f\"   Impact: +1 point review score changes LTV by R$ {slope:.2f}\")\n",
    "        \n",
    "        # C) LTV vs Customer Density (if available)\n",
    "        if 'avg_ltv' in df_geo.columns and 'customer_density' in df_geo.columns:\n",
    "            corr_ltv_density = df_geo['avg_ltv'].corr(df_geo['customer_density'])\n",
    "            print(f\"\\nC) LTV vs Customer Density Correlation: {corr_ltv_density:.3f}\")\n",
    "            \n",
    "            fig6c = px.scatter(\n",
    "                df_geo,\n",
    "                x='customer_density',\n",
    "                y='avg_ltv',\n",
    "                trendline='ols',\n",
    "                hover_name='state_code',\n",
    "                hover_data=['state_name', 'total_customers'],\n",
    "                title='LTV vs Customer Density',\n",
    "                labels={'customer_density': 'Customer Density (per 100k hab)', 'avg_ltv': 'Average LTV (R$)'}\n",
    "            )\n",
    "            \n",
    "            fig6c.update_layout(height=500)\n",
    "            fig6c.show()\n",
    "        \n",
    "        # Insights\n",
    "        print(\"\\n=== INSIGHTS ===\")\n",
    "        \n",
    "        # Find strongest correlation\n",
    "        if len(corr_matrix) > 0:\n",
    "            # Exclude self-correlations (diagonal) and flatten the matrix\n",
    "            corr_values = corr_matrix.unstack()\n",
    "            corr_values = corr_values[corr_values != 1]  # Remove self-correlations\n",
    "            \n",
    "            if len(corr_values) > 0:\n",
    "                strongest_corr = corr_values.abs().idxmax()\n",
    "                strongest_value = corr_matrix.loc[strongest_corr[0], strongest_corr[1]]\n",
    "                \n",
    "                print(f\"1. Strongest correlation: {strongest_corr[0]} vs {strongest_corr[1]} (r={strongest_value:.3f})\")\n",
    "        \n",
    "        # Find weakest correlation (excluding LTV with itself)\n",
    "        ltv_correlations = corr_matrix['avg_ltv'].drop('avg_ltv', errors='ignore')\n",
    "        if len(ltv_correlations) > 0:\n",
    "            weakest_corr_var = ltv_correlations.abs().idxmin()\n",
    "            weakest_corr_value = ltv_correlations[weakest_corr_var]\n",
    "            print(f\"2. Weakest LTV correlation: LTV vs {weakest_corr_var} (r={weakest_corr_value:.3f})\")\n",
    "        \n",
    "        # Operational implications\n",
    "        if 'avg_delivery_days' in df_geo.columns and 'avg_ltv' in df_geo.columns:\n",
    "            print(f\"3. Delivery optimization ROI: Improving delivery speed could increase LTV\")\n",
    "        \n",
    "        if 'avg_review_score' in df_geo.columns and 'avg_ltv' in df_geo.columns:\n",
    "            print(f\"4. Review impact: Higher customer satisfaction correlates with higher LTV\")\n",
    "        \n",
    "        # Causation vs correlation discussion\n",
    "        print(\"5. Note: Correlation does not imply causation. Further testing needed to confirm causal relationships.\")\n",
    "        \n",
    "        # Recommendations based on correlations\n",
    "        print(\"6. Recommendations:\")\n",
    "        if 'avg_delivery_days' in available_columns and abs(corr_ltv_delivery) > 0.3:\n",
    "            print(\"   - Prioritize delivery optimization in high-LTV states\")\n",
    "        \n",
    "        if 'avg_review_score' in available_columns and corr_ltv_reviews > 0.3:\n",
    "            print(\"   - Implement customer satisfaction programs in low-review states\")\n",
    "        \n",
    "        # Variables that don't correlate\n",
    "        low_corr_vars = []\n",
    "        if 'avg_ltv' in df_geo.columns:\n",
    "            for col in available_columns:\n",
    "                if col != 'avg_ltv':\n",
    "                    corr_value = df_geo['avg_ltv'].corr(df_geo[col])\n",
    "                    if abs(corr_value) < 0.2:\n",
    "                        low_corr_vars.append(col)\n",
    "        \n",
    "        if low_corr_vars:\n",
    "            print(f\"7. Low correlation variables: {', '.join(low_corr_vars)} - may not be good LTV predictors\")\n",
    "            \n",
    "    else:\n",
    "        print(\"Insufficient columns for correlation analysis\")\n",
    "else:\n",
    "    print(\"Insufficient data for correlation analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518cf098",
   "metadata": {},
   "source": [
    "## 9. STATE SEGMENTATION (CLUSTERING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8e605b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== STATE CLUSTERING ANALYSIS ===\\n\")\n",
    "\n",
    "if len(df_geo) > 0:\n",
    "    # Select features for clustering\n",
    "    features = ['avg_ltv', 'total_customers', 'avg_order_value', \n",
    "                'avg_delivery_days', 'avg_review_score']\n",
    "    \n",
    "    # Check which features are available\n",
    "    available_features = [f for f in features if f in df_geo.columns]\n",
    "    \n",
    "    if len(available_features) >= 3:\n",
    "        # Prepare data for clustering\n",
    "        clustering_data = df_geo[available_features].copy()\n",
    "        \n",
    "        # Handle missing values\n",
    "        clustering_data = clustering_data.dropna()\n",
    "        \n",
    "        if len(clustering_data) > 5:  # Need enough data for clustering\n",
    "            # Standardize features\n",
    "            from sklearn.preprocessing import StandardScaler\n",
    "            scaler = StandardScaler()\n",
    "            X_scaled = scaler.fit_transform(clustering_data)\n",
    "            \n",
    "            # Visualization 7: Elbow Method\n",
    "            from sklearn.cluster import KMeans\n",
    "            \n",
    "            inertias = []\n",
    "            K_range = range(2, 9)\n",
    "            \n",
    "            for k in K_range:\n",
    "                kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "                kmeans.fit(X_scaled)\n",
    "                inertias.append(kmeans.inertia_)\n",
    "            \n",
    "            plt.figure(figsize=(10, 6))\n",
    "            plt.plot(K_range, inertias, 'bx-')\n",
    "            plt.xlabel('Number of clusters (k)')\n",
    "            plt.ylabel('Inertia')\n",
    "            plt.title('Elbow Method for Optimal k')\n",
    "            plt.grid(True)\n",
    "            plt.show()\n",
    "            \n",
    "            # Choose k based on elbow (usually k=3 or 4)\n",
    "            optimal_k = 4  # You can adjust this based on the elbow plot\n",
    "            print(f\"Selected number of clusters: {optimal_k}\")\n",
    "            \n",
    "            # Apply K-Means\n",
    "            kmeans = KMeans(n_clusters=optimal_k, random_state=42, n_init=10)\n",
    "            clusters = kmeans.fit_predict(X_scaled)\n",
    "            \n",
    "            # Add cluster labels to original data\n",
    "            clustering_data['cluster'] = clusters\n",
    "            df_geo_clustered = df_geo.copy()\n",
    "            df_geo_clustered = df_geo_clustered.loc[clustering_data.index]\n",
    "            df_geo_clustered['cluster'] = clusters\n",
    "            \n",
    "            # Visualization 8: Scatter 2D (PCA)\n",
    "            from sklearn.decomposition import PCA\n",
    "            \n",
    "            pca = PCA(n_components=2)\n",
    "            X_pca = pca.fit_transform(X_scaled)\n",
    "            \n",
    "            fig8 = px.scatter(\n",
    "                x=X_pca[:, 0],\n",
    "                y=X_pca[:, 1],\n",
    "                color=clusters.astype(str),\n",
    "                hover_name=df_geo_clustered['state_code'],\n",
    "                hover_data=['state_name', 'avg_ltv', 'total_customers'],\n",
    "                title=f'State Clusters (K={optimal_k}) - PCA Visualization',\n",
    "                labels={'x': 'Principal Component 1', 'y': 'Principal Component 2', 'color': 'Cluster'},\n",
    "                color_discrete_sequence=px.colors.qualitative.Set1\n",
    "            )\n",
    "            \n",
    "            fig8.update_layout(height=600)\n",
    "            fig8.show()\n",
    "            \n",
    "            # Analyze clusters\n",
    "            print(\"\\n=== CLUSTER ANALYSIS ===\")\n",
    "            \n",
    "            cluster_summary = []\n",
    "            for cluster_num in range(optimal_k):\n",
    "                cluster_states = df_geo_clustered[df_geo_clustered['cluster'] == cluster_num]\n",
    "                \n",
    "                if len(cluster_states) > 0:\n",
    "                    cluster_info = {\n",
    "                        'cluster': cluster_num,\n",
    "                        'size': len(cluster_states),\n",
    "                        'states': cluster_states['state_code'].tolist(),\n",
    "                        'avg_ltv': cluster_states['avg_ltv'].mean(),\n",
    "                        'avg_customers': cluster_states['total_customers'].mean(),\n",
    "                        'avg_aov': cluster_states['avg_order_value'].mean() if 'avg_order_value' in cluster_states.columns else 0,\n",
    "                        'avg_delivery': cluster_states['avg_delivery_days'].mean() if 'avg_delivery_days' in cluster_states.columns else 0\n",
    "                    }\n",
    "                    cluster_summary.append(cluster_info)\n",
    "            \n",
    "            # Sort clusters by LTV\n",
    "            cluster_summary_sorted = sorted(cluster_summary, key=lambda x: x['avg_ltv'], reverse=True)\n",
    "            \n",
    "            for i, cluster in enumerate(cluster_summary_sorted):\n",
    "                print(f\"\\nCluster {cluster['cluster']} (Rank {i+1} by LTV):\")\n",
    "                print(f\"  Size: {cluster['size']} states\")\n",
    "                print(f\"  States: {', '.join(cluster['states'])}\")\n",
    "                print(f\"  Avg LTV: R$ {cluster['avg_ltv']:.2f}\")\n",
    "                print(f\"  Avg Customers: {cluster['avg_customers']:.0f}\")\n",
    "                print(f\"  Avg AOV: R$ {cluster['avg_aov']:.2f}\")\n",
    "                print(f\"  Avg Delivery: {cluster['avg_delivery']:.1f} days\")\n",
    "                \n",
    "                # Assign descriptive name\n",
    "                if i == 0:\n",
    "                    cluster_name = \"High Value States\"\n",
    "                elif cluster['avg_customers'] > df_geo['total_customers'].median():\n",
    "                    cluster_name = \"High Volume States\"\n",
    "                elif cluster['avg_ltv'] < df_geo['avg_ltv'].median():\n",
    "                    cluster_name = \"Optimization Needed\"\n",
    "                else:\n",
    "                    cluster_name = \"Growth Potential\"\n",
    "                \n",
    "                print(f\"  Profile: {cluster_name}\")\n",
    "            \n",
    "            # Insights\n",
    "            print(\"\\n=== INSIGHTS ===\")\n",
    "            \n",
    "            # Identify ideal cluster\n",
    "            ideal_cluster = cluster_summary_sorted[0]\n",
    "            print(f\"1. Ideal cluster identified: Cluster {ideal_cluster['cluster']} ({ideal_cluster['size']} states)\")\n",
    "            print(f\"   Characteristics: High LTV (R$ {ideal_cluster['avg_ltv']:.2f}), {ideal_cluster['states']}\")\n",
    "            \n",
    "            # Identify cluster with most potential\n",
    "            potential_clusters = []\n",
    "            for cluster in cluster_summary_sorted:\n",
    "                if (cluster['avg_customers'] < df_geo['total_customers'].median() and \n",
    "                    cluster['avg_ltv'] > df_geo['avg_ltv'].median()):\n",
    "                    potential_clusters.append(cluster)\n",
    "            \n",
    "            if potential_clusters:\n",
    "                print(f\"2. Cluster with highest growth potential: Cluster {potential_clusters[0]['cluster']}\")\n",
    "                print(f\"   Reason: Low volume but high LTV - perfect for expansion\")\n",
    "            \n",
    "            # Identify clusters requiring attention\n",
    "            attention_clusters = []\n",
    "            for cluster in cluster_summary_sorted:\n",
    "                if (cluster['avg_customers'] > df_geo['total_customers'].median() and \n",
    "                    cluster['avg_ltv'] < df_geo['avg_ltv'].median()):\n",
    "                    attention_clusters.append(cluster)\n",
    "            \n",
    "            if attention_clusters:\n",
    "                print(f\"3. Cluster requiring attention: Cluster {attention_clusters[0]['cluster']}\")\n",
    "                print(f\"   Reason: High volume but low LTV - optimization needed\")\n",
    "            \n",
    "            # Differentiated strategies\n",
    "            print(\"4. Differentiated strategies by cluster:\")\n",
    "            for cluster in cluster_summary_sorted:\n",
    "                if cluster == ideal_cluster:\n",
    "                    print(f\"   Cluster {cluster['cluster']}: Maintain leadership, premium loyalty programs\")\n",
    "                elif cluster in potential_clusters:\n",
    "                    print(f\"   Cluster {cluster['cluster']}: Aggressive marketing, market expansion\")\n",
    "                elif cluster in attention_clusters:\n",
    "                    print(f\"   Cluster {cluster['cluster']}: Customer retention, upsell/cross-sell\")\n",
    "                else:\n",
    "                    print(f\"   Cluster {cluster['cluster']}: Test new approaches, improve operations\")\n",
    "                    \n",
    "        else:\n",
    "            print(\"Insufficient data points for clustering\")\n",
    "    else:\n",
    "        print(\"Insufficient features available for clustering\")\n",
    "else:\n",
    "    print(\"Insufficient data for clustering analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8de443d",
   "metadata": {},
   "source": [
    "## 10. MARKET OPPORTUNITY ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0117e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== MARKET OPPORTUNITY ANALYSIS ===\\n\")\n",
    "\n",
    "if len(df_geo) > 0 and 'avg_ltv' in df_geo.columns and 'region' in df_geo.columns:\n",
    "    # Calculate LTV gap\n",
    "    df_geo['region_max_ltv'] = df_geo.groupby('region')['avg_ltv'].transform('max')\n",
    "    df_geo['ltv_gap'] = df_geo['region_max_ltv'] - df_geo['avg_ltv']\n",
    "    \n",
    "    # Calculate LTV gap percentage\n",
    "    df_geo['ltv_gap_pct'] = (df_geo['ltv_gap'] / df_geo['avg_ltv'] * 100) if df_geo['avg_ltv'] != 0 else 0\n",
    "    \n",
    "    # Calculate revenue opportunity\n",
    "    df_geo['revenue_opportunity'] = df_geo['total_customers'] * df_geo['ltv_gap']\n",
    "    \n",
    "    # Calculate normalized scores\n",
    "    df_geo['volume_score'] = 0\n",
    "    df_geo['gap_score'] = 0\n",
    "    \n",
    "    if df_geo['total_customers'].max() > df_geo['total_customers'].min():\n",
    "        df_geo['volume_score'] = (df_geo['total_customers'] - df_geo['total_customers'].min()) / \\\n",
    "                                 (df_geo['total_customers'].max() - df_geo['total_customers'].min())\n",
    "    \n",
    "    if df_geo['ltv_gap_pct'].max() > df_geo['ltv_gap_pct'].min():\n",
    "        df_geo['gap_score'] = (df_geo['ltv_gap_pct'] - df_geo['ltv_gap_pct'].min()) / \\\n",
    "                              (df_geo['ltv_gap_pct'].max() - df_geo['ltv_gap_pct'].min())\n",
    "    \n",
    "    # Calculate opportunity score (60% gap, 40% volume)\n",
    "    df_geo['opportunity_score'] = 0.6 * df_geo['gap_score'] + 0.4 * df_geo['volume_score']\n",
    "    \n",
    "    # Sort by opportunity score\n",
    "    df_opportunity = df_geo.sort_values('opportunity_score', ascending=False).reset_index(drop=True)\n",
    "    \n",
    "    # Visualization 9: Top 10 Opportunities\n",
    "    top_10_opportunities = df_opportunity.head(10)\n",
    "    \n",
    "    fig9 = px.bar(\n",
    "        top_10_opportunities,\n",
    "        y='state_code',\n",
    "        x='revenue_opportunity',\n",
    "        color='ltv_gap_pct',\n",
    "        orientation='h',\n",
    "        title='Top 10 Revenue Opportunities by State',\n",
    "        labels={\n",
    "            'revenue_opportunity': 'Revenue Opportunity (R$)',\n",
    "            'state_code': 'State',\n",
    "            'ltv_gap_pct': 'LTV Gap %'\n",
    "        },\n",
    "        color_continuous_scale='Viridis',\n",
    "        text='revenue_opportunity'\n",
    "    )\n",
    "    \n",
    "    fig9.update_traces(\n",
    "        texttemplate='R$ %{text:,.0f}',\n",
    "        textposition='outside'\n",
    "    )\n",
    "    \n",
    "    fig9.update_layout(\n",
    "        height=600,\n",
    "        yaxis={'categoryorder': 'total ascending'},\n",
    "        coloraxis_colorbar=dict(title=\"LTV Gap %\"),\n",
    "        xaxis_title=\"Revenue Opportunity (R$)\",\n",
    "        yaxis_title=\"State\"\n",
    "    )\n",
    "    \n",
    "    fig9.show()\n",
    "    \n",
    "    # Create opportunity table\n",
    "    print(\"TOP 10 STATES FOR EXPANSION:\")\n",
    "    print(\"=\" * 120)\n",
    "    \n",
    "    opportunity_table = df_opportunity.head(10)[[\n",
    "        'state_code', 'state_name', 'region', \n",
    "        'opportunity_score', 'ltv_gap_pct', 'revenue_opportunity',\n",
    "        'avg_ltv', 'region_max_ltv', 'total_customers'\n",
    "    ]].copy()\n",
    "    \n",
    "    opportunity_table['current_ltv'] = opportunity_table['avg_ltv']\n",
    "    opportunity_table['target_ltv'] = opportunity_table['region_max_ltv']\n",
    "    opportunity_table['roi_estimated'] = opportunity_table['revenue_opportunity'] / opportunity_table['total_customers'] * 100\n",
    "    \n",
    "    # Format the table\n",
    "    display_table = opportunity_table[[\n",
    "        'state_code', 'opportunity_score', 'ltv_gap_pct', \n",
    "        'revenue_opportunity', 'current_ltv', 'target_ltv'\n",
    "    ]].round(2)\n",
    "    \n",
    "    display_table['opportunity_score'] = display_table['opportunity_score'].round(3)\n",
    "    display_table['revenue_opportunity'] = display_table['revenue_opportunity'].apply(lambda x: f\"R$ {x:,.0f}\")\n",
    "    display_table['current_ltv'] = display_table['current_ltv'].apply(lambda x: f\"R$ {x:.2f}\")\n",
    "    display_table['target_ltv'] = display_table['target_ltv'].apply(lambda x: f\"R$ {x:.2f}\")\n",
    "    \n",
    "    print(display_table.to_string(index=False))\n",
    "    \n",
    "    # Calculate total opportunity\n",
    "    total_revenue_opportunity = df_geo['revenue_opportunity'].sum()\n",
    "    total_current_revenue = df_geo['total_revenue'].sum()\n",
    "    opportunity_pct = (total_revenue_opportunity / total_current_revenue * 100) if total_current_revenue != 0 else 0\n",
    "    \n",
    "    print(f\"\\nTotal Revenue Opportunity: R$ {total_revenue_opportunity:,.0f}\")\n",
    "    print(f\"Percentage of Current Revenue: {opportunity_pct:.1f}%\")\n",
    "    \n",
    "    # Insights\n",
    "    print(\"\\n=== INSIGHTS ===\")\n",
    "    \n",
    "    # Top 3 priority states\n",
    "    top_3_priority = df_opportunity.head(3)['state_code'].tolist()\n",
    "    top_3_opportunity = df_opportunity.head(3)['revenue_opportunity'].sum()\n",
    "    print(f\"1. Top 3 priority states for expansion: {', '.join(top_3_priority)}\")\n",
    "    print(f\"   Combined opportunity: R$ {top_3_opportunity:,.0f}\")\n",
    "    \n",
    "    # Quick wins (high score, easy execution)\n",
    "    # Assuming \"easy execution\" means states with high volume score (existing infrastructure)\n",
    "    quick_wins = df_opportunity[\n",
    "        (df_opportunity['opportunity_score'] > df_opportunity['opportunity_score'].median()) &\n",
    "        (df_opportunity['volume_score'] > 0.5)\n",
    "    ].head(5)\n",
    "    \n",
    "    if len(quick_wins) > 0:\n",
    "        print(f\"2. Quick wins (high opportunity, existing infrastructure):\")\n",
    "        for _, row in quick_wins.iterrows():\n",
    "            print(f\"   {row['state_code']}: R$ {row['revenue_opportunity']:,.0f} opportunity\")\n",
    "    \n",
    "    # Long-term opportunities\n",
    "    long_term = df_opportunity[\n",
    "        (df_opportunity['opportunity_score'] > df_opportunity['opportunity_score'].median()) &\n",
    "        (df_opportunity['volume_score'] < 0.3)\n",
    "    ].head(3)\n",
    "    \n",
    "    if len(long_term) > 0:\n",
    "        print(f\"3. Long-term opportunities (high potential, low current volume):\")\n",
    "        for _, row in long_term.iterrows():\n",
    "            print(f\"   {row['state_code']}: R$ {row['revenue_opportunity']:,.0f} opportunity\")\n",
    "    \n",
    "    # Investment vs return\n",
    "    estimated_investment = total_revenue_opportunity * 0.1  # Assuming 10% investment of opportunity\n",
    "    estimated_roi = (total_revenue_opportunity / estimated_investment * 100) if estimated_investment != 0 else 0\n",
    "    \n",
    "    print(f\"4. Estimated investment needed: R$ {estimated_investment:,.0f}\")\n",
    "    print(f\"5. Projected ROI: {estimated_roi:.1f}%\")\n",
    "    \n",
    "else:\n",
    "    print(\"Insufficient data for market opportunity analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e666bea6",
   "metadata": {},
   "source": [
    "## 11. MARKET PENETRATION ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daab599e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== MARKET PENETRATION ANALYSIS ===\\n\")\n",
    "\n",
    "# Note: This section requires population data. If not available in the dataset,\n",
    "# we'll use alternative approaches or skip certain calculations.\n",
    "\n",
    "if len(df_geo) > 0:\n",
    "    # Check if we have population data\n",
    "    if 'customer_density' in df_geo.columns:\n",
    "        # Use customer_density as proxy for penetration\n",
    "        df_geo['penetration_rate'] = df_geo['customer_density']\n",
    "        print(\"Using customer_density as penetration proxy\")\n",
    "    else:\n",
    "        # Create a simple penetration metric based on customers\n",
    "        # This is a relative penetration metric\n",
    "        max_customers = df_geo['total_customers'].max()\n",
    "        if max_customers > 0:\n",
    "            df_geo['penetration_rate'] = (df_geo['total_customers'] / max_customers) * 100\n",
    "            print(\"Using relative customer count as penetration proxy\")\n",
    "        else:\n",
    "            print(\"Insufficient data for penetration analysis\")\n",
    "            df_geo['penetration_rate'] = 0\n",
    "    \n",
    "    if 'penetration_rate' in df_geo.columns:\n",
    "        # Calculate penetration thresholds\n",
    "        median_penetration = df_geo['penetration_rate'].median()\n",
    "        median_ltv = df_geo['avg_ltv'].median()\n",
    "        \n",
    "        # Classify states by penetration-LTV quadrant\n",
    "        df_geo['penetration_quadrant'] = 'Unknown'\n",
    "        \n",
    "        for idx, row in df_geo.iterrows():\n",
    "            if row['penetration_rate'] >= median_penetration and row['avg_ltv'] >= median_ltv:\n",
    "                df_geo.at[idx, 'penetration_quadrant'] = 'High Penetration, High LTV'\n",
    "            elif row['penetration_rate'] >= median_penetration and row['avg_ltv'] < median_ltv:\n",
    "                df_geo.at[idx, 'penetration_quadrant'] = 'High Penetration, Low LTV'\n",
    "            elif row['penetration_rate'] < median_penetration and row['avg_ltv'] >= median_ltv:\n",
    "                df_geo.at[idx, 'penetration_quadrant'] = 'Low Penetration, High LTV'\n",
    "            else:\n",
    "                df_geo.at[idx, 'penetration_quadrant'] = 'Low Penetration, Low LTV'\n",
    "        \n",
    "        # Visualization 10: Scatter Plot - Penetration vs LTV\n",
    "        fig10 = px.scatter(\n",
    "            df_geo,\n",
    "            x='penetration_rate',\n",
    "            y='avg_ltv',\n",
    "            size='total_revenue',\n",
    "            color='region',\n",
    "            hover_name='state_code',\n",
    "            hover_data=['state_name', 'total_customers', 'penetration_quadrant'],\n",
    "            title='Market Penetration vs LTV',\n",
    "            labels={\n",
    "                'penetration_rate': 'Market Penetration Rate',\n",
    "                'avg_ltv': 'Average LTV (R$)',\n",
    "                'total_revenue': 'Total Revenue',\n",
    "                'region': 'Region'\n",
    "            },\n",
    "            size_max=50\n",
    "        )\n",
    "        \n",
    "        # Add quadrant lines\n",
    "        fig10.add_shape(\n",
    "            type=\"line\",\n",
    "            x0=median_penetration,\n",
    "            y0=df_geo['avg_ltv'].min(),\n",
    "            x1=median_penetration,\n",
    "            y1=df_geo['avg_ltv'].max(),\n",
    "            line=dict(color=\"gray\", width=1, dash=\"dash\")\n",
    "        )\n",
    "        \n",
    "        fig10.add_shape(\n",
    "            type=\"line\",\n",
    "            x0=df_geo['penetration_rate'].min(),\n",
    "            y0=median_ltv,\n",
    "            x1=df_geo['penetration_rate'].max(),\n",
    "            y1=median_ltv,\n",
    "            line=dict(color=\"gray\", width=1, dash=\"dash\")\n",
    "        )\n",
    "        \n",
    "        # Add quadrant annotations\n",
    "        fig10.add_annotation(\n",
    "            x=df_geo['penetration_rate'].max() * 0.75,\n",
    "            y=df_geo['avg_ltv'].max() * 0.75,\n",
    "            text=\"High Penetration<br>High LTV\",\n",
    "            showarrow=False,\n",
    "            font=dict(size=10)\n",
    "        )\n",
    "        \n",
    "        fig10.add_annotation(\n",
    "            x=df_geo['penetration_rate'].max() * 0.75,\n",
    "            y=df_geo['avg_ltv'].min() * 1.25,\n",
    "            text=\"High Penetration<br>Low LTV\",\n",
    "            showarrow=False,\n",
    "            font=dict(size=10)\n",
    "        )\n",
    "        \n",
    "        fig10.add_annotation(\n",
    "            x=df_geo['penetration_rate'].min() * 1.25,\n",
    "            y=df_geo['avg_ltv'].max() * 0.75,\n",
    "            text=\"Low Penetration<br>High LTV\",\n",
    "            showarrow=False,\n",
    "            font=dict(size=10)\n",
    "        )\n",
    "        \n",
    "        fig10.add_annotation(\n",
    "            x=df_geo['penetration_rate'].min() * 1.25,\n",
    "            y=df_geo['avg_ltv'].min() * 1.25,\n",
    "            text=\"Low Penetration<br>Low LTV\",\n",
    "            showarrow=False,\n",
    "            font=dict(size=10)\n",
    "        )\n",
    "        \n",
    "        fig10.update_layout(\n",
    "            height=600,\n",
    "            xaxis_title=\"Market Penetration Rate\",\n",
    "            yaxis_title=\"Average LTV (R$)\"\n",
    "        )\n",
    "        \n",
    "        fig10.show()\n",
    "        \n",
    "        # Calculate correlation\n",
    "        penetration_ltv_corr = df_geo['penetration_rate'].corr(df_geo['avg_ltv'])\n",
    "        \n",
    "        # Quadrant analysis\n",
    "        quadrant_counts = df_geo['penetration_quadrant'].value_counts()\n",
    "        \n",
    "        print(\"\\n=== PENETRATION ANALYSIS ===\")\n",
    "        print(f\"Correlation between penetration and LTV: {penetration_ltv_corr:.3f}\")\n",
    "        print(\"\\nQuadrant Distribution:\")\n",
    "        for quadrant, count in quadrant_counts.items():\n",
    "            print(f\"  {quadrant}: {count} states\")\n",
    "        \n",
    "        # Detailed quadrant analysis\n",
    "        print(\"\\n=== QUADRANT INSIGHTS ===\")\n",
    "        \n",
    "        for quadrant in ['High Penetration, High LTV', 'High Penetration, Low LTV',\n",
    "                         'Low Penetration, High LTV', 'Low Penetration, Low LTV']:\n",
    "            quadrant_states = df_geo[df_geo['penetration_quadrant'] == quadrant]\n",
    "            if len(quadrant_states) > 0:\n",
    "                states_list = ', '.join(quadrant_states['state_code'].tolist())\n",
    "                print(f\"\\n{quadrant}:\")\n",
    "                print(f\"  States: {states_list}\")\n",
    "                \n",
    "                if quadrant == 'Low Penetration, High LTV':\n",
    "                    print(f\"  Strategy: High expansion priority (sweet spot)\")\n",
    "                elif quadrant == 'High Penetration, Low LTV':\n",
    "                    print(f\"  Strategy: Focus on upsell/cross-sell\")\n",
    "                elif quadrant == 'High Penetration, High LTV':\n",
    "                    print(f\"  Strategy: Maintain leadership, premium services\")\n",
    "                else:\n",
    "                    print(f\"  Strategy: Test market fit, consider pilot programs\")\n",
    "        \n",
    "        # Insights\n",
    "        print(\"\\n=== INSIGHTS ===\")\n",
    "        \n",
    "        # Identify saturated vs underpenetrated markets\n",
    "        saturated_states = df_geo[df_geo['penetration_quadrant'] == 'High Penetration, Low LTV']\n",
    "        underpenetrated_states = df_geo[df_geo['penetration_quadrant'] == 'Low Penetration, High LTV']\n",
    "        \n",
    "        if len(saturated_states) > 0:\n",
    "            print(f\"1. Saturated markets (high penetration, low LTV): {len(saturated_states)} states\")\n",
    "            print(f\"   Examples: {', '.join(saturated_states.head(3)['state_code'].tolist())}\")\n",
    "        \n",
    "        if len(underpenetrated_states) > 0:\n",
    "            print(f\"2. Underpenetrated markets (low penetration, high LTV): {len(underpenetrated_states)} states\")\n",
    "            print(f\"   Examples: {', '.join(underpenetrated_states.head(3)['state_code'].tolist())}\")\n",
    "        \n",
    "        # Sweet spot analysis\n",
    "        sweet_spot_states = df_geo[df_geo['penetration_quadrant'] == 'Low Penetration, High LTV']\n",
    "        if len(sweet_spot_states) > 0:\n",
    "            sweet_spot_revenue = sweet_spot_states['total_revenue'].sum()\n",
    "            total_revenue = df_geo['total_revenue'].sum()\n",
    "            sweet_spot_pct = (sweet_spot_revenue / total_revenue * 100) if total_revenue != 0 else 0\n",
    "            print(f\"3. Sweet spot potential: {len(sweet_spot_states)} states with {sweet_spot_pct:.1f}% of current revenue\")\n",
    "        \n",
    "        # Strategies by quadrant\n",
    "        print(\"4. Strategic approaches by quadrant:\")\n",
    "        print(\"   - High Penetration, High LTV: Defend position, increase switching costs\")\n",
    "        print(\"   - High Penetration, Low LTV: Improve customer value, reduce churn\")\n",
    "        print(\"   - Low Penetration, High LTV: Aggressive acquisition, market education\")\n",
    "        print(\"   - Low Penetration, Low LTV: Test channels, validate product-market fit\")\n",
    "        \n",
    "else:\n",
    "    print(\"Insufficient data for penetration analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40efdf7",
   "metadata": {},
   "source": [
    "## 12. STRATEGIC RECOMMENDATIONS BY STATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d20978e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== STRATEGIC RECOMMENDATIONS BY STATE ===\\n\")\n",
    "\n",
    "if len(df_geo) > 0 and 'avg_ltv' in df_geo.columns and 'total_customers' in df_geo.columns:\n",
    "    # Define state groups based on percentiles\n",
    "    ltv_75th = df_geo['avg_ltv'].quantile(0.75)\n",
    "    ltv_25th = df_geo['avg_ltv'].quantile(0.25)\n",
    "    \n",
    "    customers_75th = df_geo['total_customers'].quantile(0.75)\n",
    "    customers_25th = df_geo['total_customers'].quantile(0.25)\n",
    "    \n",
    "    # Classify states into 4 groups\n",
    "    df_geo['strategy_group'] = 'Unknown'\n",
    "    \n",
    "    for idx, row in df_geo.iterrows():\n",
    "        if row['avg_ltv'] >= ltv_75th and row['total_customers'] >= customers_75th:\n",
    "            df_geo.at[idx, 'strategy_group'] = 'High Performers'\n",
    "        elif row['avg_ltv'] >= ltv_25th and row['avg_ltv'] < ltv_75th and row['total_customers'] >= customers_25th:\n",
    "            df_geo.at[idx, 'strategy_group'] = 'Growth Opportunities'\n",
    "        elif row['total_customers'] >= customers_75th and row['avg_ltv'] < ltv_25th:\n",
    "            df_geo.at[idx, 'strategy_group'] = 'Optimization Needed'\n",
    "        else:\n",
    "            df_geo.at[idx, 'strategy_group'] = 'Early Stage'\n",
    "    \n",
    "    # Create recommendations dataframe\n",
    "    recommendations = []\n",
    "    \n",
    "    for idx, row in df_geo.iterrows():\n",
    "        rec = {\n",
    "            'state_code': row['state_code'],\n",
    "            'state_name': row['state_name'],\n",
    "            'strategy_group': row['strategy_group'],\n",
    "            'current_ltv': row['avg_ltv'],\n",
    "            'total_customers': row['total_customers'],\n",
    "            'action_primary': '',\n",
    "            'primary_channel': '',\n",
    "            'budget_suggested': 0,\n",
    "            'roi_expected': 0\n",
    "        }\n",
    "        \n",
    "        # Set recommendations based on group\n",
    "        if row['strategy_group'] == 'High Performers':\n",
    "            rec['action_primary'] = 'Premium loyalty programs, exclusive offers'\n",
    "            rec['primary_channel'] = 'Email, App notifications'\n",
    "            rec['budget_suggested'] = row['total_customers'] * 10  # R$10 per customer\n",
    "            rec['roi_expected'] = 25  # 25% ROI\n",
    "            rec['ltv_target'] = row['avg_ltv'] * 1.1  # 10% increase\n",
    "            \n",
    "        elif row['strategy_group'] == 'Growth Opportunities':\n",
    "            rec['action_primary'] = 'Targeted marketing campaigns, improve onboarding'\n",
    "            rec['primary_channel'] = 'Social media, Search ads'\n",
    "            rec['budget_suggested'] = row['total_customers'] * 20  # R$20 per customer\n",
    "            rec['roi_expected'] = 40  # 40% ROI\n",
    "            rec['ltv_target'] = row['avg_ltv'] * 1.25  # 25% increase\n",
    "            \n",
    "        elif row['strategy_group'] == 'Optimization Needed':\n",
    "            rec['action_primary'] = 'Cross-sell/upsell programs, improve retention'\n",
    "            rec['primary_channel'] = 'In-app messages, Retargeting'\n",
    "            rec['budget_suggested'] = row['total_customers'] * 15  # R$15 per customer\n",
    "            rec['roi_expected'] = 30  # 30% ROI\n",
    "            rec['ltv_target'] = row['avg_ltv'] * 1.2  # 20% increase\n",
    "            \n",
    "        else:  # Early Stage\n",
    "            rec['action_primary'] = 'Test marketing channels, validate product-market fit'\n",
    "            rec['primary_channel'] = 'Pilot campaigns, Partnerships'\n",
    "            rec['budget_suggested'] = row['total_customers'] * 30  # R$30 per customer\n",
    "            rec['roi_expected'] = 15  # 15% ROI\n",
    "            rec['ltv_target'] = row['avg_ltv'] * 1.5  # 50% increase (from low base)\n",
    "        \n",
    "        recommendations.append(rec)\n",
    "    \n",
    "    recommendations_df = pd.DataFrame(recommendations)\n",
    "    \n",
    "    # Visualization 11: 2x2 Matrix\n",
    "    fig11 = px.scatter(\n",
    "        df_geo,\n",
    "        x='total_customers',\n",
    "        y='avg_ltv',\n",
    "        color='strategy_group',\n",
    "        hover_name='state_code',\n",
    "        hover_data=['state_name', 'region', 'avg_order_value'],\n",
    "        title='Strategic Grouping: Volume vs LTV Matrix',\n",
    "        labels={\n",
    "            'total_customers': 'Total Customers',\n",
    "            'avg_ltv': 'Average LTV (R$)',\n",
    "            'strategy_group': 'Strategy Group'\n",
    "        },\n",
    "        log_x=True,  # Log scale for better visualization\n",
    "        color_discrete_sequence=['green', 'blue', 'orange', 'red']\n",
    "    )\n",
    "    \n",
    "    # Add group boundary lines\n",
    "    fig11.add_shape(\n",
    "        type=\"line\",\n",
    "        x0=customers_75th,\n",
    "        y0=df_geo['avg_ltv'].min(),\n",
    "        x1=customers_75th,\n",
    "        y1=df_geo['avg_ltv'].max(),\n",
    "        line=dict(color=\"gray\", width=1, dash=\"dash\")\n",
    "    )\n",
    "    \n",
    "    fig11.add_shape(\n",
    "        type=\"line\",\n",
    "        x0=df_geo['total_customers'].min(),\n",
    "        y0=ltv_75th,\n",
    "        x1=df_geo['total_customers'].max(),\n",
    "        y1=ltv_75th,\n",
    "        line=dict(color=\"gray\", width=1, dash=\"dash\")\n",
    "    )\n",
    "    \n",
    "    fig11.add_shape(\n",
    "        type=\"line\",\n",
    "        x0=df_geo['total_customers'].min(),\n",
    "        y0=ltv_25th,\n",
    "        x1=df_geo['total_customers'].max(),\n",
    "        y1=ltv_25th,\n",
    "        line=dict(color=\"gray\", width=1, dash=\"dot\")\n",
    "    )\n",
    "    \n",
    "    fig11.add_shape(\n",
    "        type=\"line\",\n",
    "        x0=customers_25th,\n",
    "        y0=df_geo['avg_ltv'].min(),\n",
    "        x1=customers_25th,\n",
    "        y1=df_geo['avg_ltv'].max(),\n",
    "        line=dict(color=\"gray\", width=1, dash=\"dot\")\n",
    "    )\n",
    "    \n",
    "    # Add group labels\n",
    "    fig11.add_annotation(\n",
    "        x=df_geo['total_customers'].max() * 0.8,\n",
    "        y=df_geo['avg_ltv'].max() * 0.9,\n",
    "        text=\"High Performers\",\n",
    "        showarrow=False,\n",
    "        font=dict(size=10, color=\"green\")\n",
    "    )\n",
    "    \n",
    "    fig11.add_annotation(\n",
    "        x=df_geo['total_customers'].max() * 0.8,\n",
    "        y=(ltv_75th + ltv_25th) / 2,\n",
    "        text=\"Growth Opportunities\",\n",
    "        showarrow=False,\n",
    "        font=dict(size=10, color=\"blue\")\n",
    "    )\n",
    "    \n",
    "    fig11.add_annotation(\n",
    "        x=df_geo['total_customers'].max() * 0.8,\n",
    "        y=df_geo['avg_ltv'].min() * 1.1,\n",
    "        text=\"Optimization Needed\",\n",
    "        showarrow=False,\n",
    "        font=dict(size=10, color=\"orange\")\n",
    "    )\n",
    "    \n",
    "    fig11.add_annotation(\n",
    "        x=df_geo['total_customers'].min() * 1.2,\n",
    "        y=df_geo['avg_ltv'].max() * 0.9,\n",
    "        text=\"Early Stage\",\n",
    "        showarrow=False,\n",
    "        font=dict(size=10, color=\"red\")\n",
    "    )\n",
    "    \n",
    "    fig11.update_layout(\n",
    "        height=600,\n",
    "        xaxis_title=\"Total Customers (log scale)\",\n",
    "        yaxis_title=\"Average LTV (R$)\"\n",
    "    )\n",
    "    \n",
    "    fig11.show()\n",
    "    \n",
    "    # Display recommendations table\n",
    "    print(\"STRATEGIC RECOMMENDATIONS BY STATE:\")\n",
    "    print(\"=\" * 120)\n",
    "    \n",
    "    display_recs = recommendations_df[[\n",
    "        'state_code', 'strategy_group', 'current_ltv', 'ltv_target',\n",
    "        'action_primary', 'primary_channel', 'budget_suggested', 'roi_expected'\n",
    "    ]].copy()\n",
    "    \n",
    "    # Format for display\n",
    "    display_recs['current_ltv'] = display_recs['current_ltv'].apply(lambda x: f\"R$ {x:.2f}\")\n",
    "    display_recs['ltv_target'] = display_recs['ltv_target'].apply(lambda x: f\"R$ {x:.2f}\")\n",
    "    display_recs['budget_suggested'] = display_recs['budget_suggested'].apply(lambda x: f\"R$ {x:,.0f}\")\n",
    "    display_recs['roi_expected'] = display_recs['roi_expected'].apply(lambda x: f\"{x}%\")\n",
    "    \n",
    "    print(display_recs.to_string(index=False))\n",
    "    \n",
    "    # Calculate summary by group\n",
    "    print(\"\\n=== STRATEGY GROUP SUMMARY ===\")\n",
    "    \n",
    "    group_summary = recommendations_df.groupby('strategy_group').agg({\n",
    "        'state_code': 'count',\n",
    "        'current_ltv': 'mean',\n",
    "        'total_customers': 'sum',\n",
    "        'budget_suggested': 'sum',\n",
    "        'roi_expected': 'mean'\n",
    "    }).reset_index()\n",
    "    \n",
    "    group_summary = group_summary.rename(columns={\n",
    "        'state_code': 'state_count',\n",
    "        'current_ltv': 'avg_ltv',\n",
    "        'roi_expected': 'avg_roi'\n",
    "    })\n",
    "    \n",
    "    print(group_summary.round(2).to_string(index=False))\n",
    "    \n",
    "    # Insights\n",
    "    print(\"\\n=== INSIGHTS ===\")\n",
    "    \n",
    "    # Priority states for each strategy\n",
    "    for group in ['High Performers', 'Growth Opportunities', 'Optimization Needed', 'Early Stage']:\n",
    "        group_states = df_geo[df_geo['strategy_group'] == group]\n",
    "        if len(group_states) > 0:\n",
    "            print(f\"\\n{group}:\")\n",
    "            print(f\"  States: {', '.join(group_states['state_code'].tolist())}\")\n",
    "            print(f\"  Count: {len(group_states)} states\")\n",
    "            \n",
    "            if len(group_states) > 0:\n",
    "                avg_ltv = group_states['avg_ltv'].mean()\n",
    "                total_customers = group_states['total_customers'].sum()\n",
    "                print(f\"  Avg LTV: R$ {avg_ltv:.2f}\")\n",
    "                print(f\"  Total Customers: {total_customers:,}\")\n",
    "    \n",
    "    # Total budget estimate\n",
    "    total_budget = recommendations_df['budget_suggested'].sum()\n",
    "    print(f\"\\nTotal Suggested Budget: R$ {total_budget:,.0f}\")\n",
    "    \n",
    "    # ROI by group\n",
    "    print(\"\\nExpected ROI by Group:\")\n",
    "    for _, row in group_summary.iterrows():\n",
    "        print(f\"  {row['strategy_group']}: {row['avg_roi']:.1f}% ROI\")\n",
    "    \n",
    "    # Timeline\n",
    "    print(\"\\nImplementation Timeline:\")\n",
    "    print(\"  Q1 2025: Focus on 'Optimization Needed' states\")\n",
    "    print(\"  Q2 2025: Expand 'Growth Opportunities' states\")\n",
    "    print(\"  Q3 2025: Scale 'High Performers' initiatives\")\n",
    "    print(\"  Q4 2025: Pilot 'Early Stage' markets\")\n",
    "    \n",
    "    # Quick wins\n",
    "    quick_wins = df_geo[\n",
    "        (df_geo['strategy_group'] == 'Optimization Needed') &\n",
    "        (df_geo['total_customers'] > df_geo['total_customers'].median())\n",
    "    ].head(3)\n",
    "    \n",
    "    if len(quick_wins) > 0:\n",
    "        print(f\"\\nQuick Wins (high impact, existing customers):\")\n",
    "        for _, row in quick_wins.iterrows():\n",
    "            print(f\"  {row['state_code']}: {row['total_customers']:,} customers, R$ {row['avg_ltv']:.2f} LTV\")\n",
    "    \n",
    "    # Risks\n",
    "    print(\"\\nKey Risks:\")\n",
    "    print(\"  1. Over-investment in low-potential 'Early Stage' markets\")\n",
    "    print(\"  2. Under-investment in high-potential 'Growth Opportunities'\")\n",
    "    print(\"  3. Neglecting 'High Performers' leading to competitive erosion\")\n",
    "    print(\"  4. Operational capacity for simultaneous state expansions\")\n",
    "    \n",
    "    # Resource needs\n",
    "    print(\"\\nResource Requirements:\")\n",
    "    print(\"  - Marketing team: +3 FTEs for campaign management\")\n",
    "    print(\"  - Tech resources: Analytics dashboard development\")\n",
    "    print(\"  - Operations: Regional customer support expansion\")\n",
    "    \n",
    "    # Export recommendations\n",
    "    recommendations_df.to_csv('state_strategic_recommendations.csv', index=False)\n",
    "    print(\"\\nRecommendations exported to 'state_strategic_recommendations.csv'\")\n",
    "    \n",
    "else:\n",
    "    print(\"Insufficient data for strategic recommendations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cecbf472",
   "metadata": {},
   "source": [
    "## 13. EXECUTIVE SUMMARY & KEY INSIGHTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd0c3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== EXECUTIVE SUMMARY & KEY INSIGHTS ===\\n\")\n",
    "\n",
    "if len(df_geo) > 0:\n",
    "    # Calculate all summary metrics dynamically\n",
    "    total_states = df_geo['state_code'].nunique()\n",
    "    total_customers = df_geo['total_customers'].sum()\n",
    "    avg_ltv_brazil = df_geo['avg_ltv'].mean()\n",
    "    max_ltv = df_geo['avg_ltv'].max()\n",
    "    min_ltv = df_geo['avg_ltv'].min()\n",
    "    ltv_range = max_ltv - min_ltv\n",
    "    \n",
    "    # Top 3 states\n",
    "    top_3_df = df_geo.nlargest(3, 'avg_ltv')\n",
    "    top_3_states = top_3_df['state_code'].tolist()\n",
    "    top_3_values = top_3_df['avg_ltv'].tolist()\n",
    "    \n",
    "    # Bottom 3 states\n",
    "    bottom_3_df = df_geo.nsmallest(3, 'avg_ltv')\n",
    "    bottom_3_states = bottom_3_df['state_code'].tolist()\n",
    "    bottom_3_values = bottom_3_df['avg_ltv'].tolist()\n",
    "    \n",
    "    # Concentration metrics\n",
    "    df_sorted_revenue = df_geo.sort_values('total_revenue', ascending=False)\n",
    "    top_5_revenue = df_sorted_revenue.head(5)['total_revenue'].sum()\n",
    "    total_revenue = df_geo['total_revenue'].sum()\n",
    "    top_5_revenue_pct = (top_5_revenue / total_revenue * 100) if total_revenue != 0 else 0\n",
    "    \n",
    "    # Regional insights\n",
    "    region_analysis = df_geo.groupby('region').agg({\n",
    "        'avg_ltv': 'mean',\n",
    "        'total_customers': 'sum',\n",
    "        'total_revenue': 'sum'\n",
    "    }).reset_index()\n",
    "    \n",
    "    best_region = region_analysis.loc[region_analysis['avg_ltv'].idxmax(), 'region']\n",
    "    best_region_ltv = region_analysis['avg_ltv'].max()\n",
    "    \n",
    "    highest_volume_region = region_analysis.loc[region_analysis['total_customers'].idxmax(), 'region']\n",
    "    highest_volume = region_analysis['total_customers'].max()\n",
    "    \n",
    "    # Correlation findings\n",
    "    correlation_findings = []\n",
    "    if 'avg_delivery_days' in df_geo.columns:\n",
    "        corr_delivery = df_geo['avg_ltv'].corr(df_geo['avg_delivery_days'])\n",
    "        correlation_findings.append(f\"LTV vs delivery: r={corr_delivery:.3f}\")\n",
    "    \n",
    "    if 'avg_review_score' in df_geo.columns:\n",
    "        corr_review = df_geo['avg_ltv'].corr(df_geo['avg_review_score'])\n",
    "        correlation_findings.append(f\"LTV vs reviews: r={corr_review:.3f}\")\n",
    "    \n",
    "    # Market opportunities\n",
    "    if 'revenue_opportunity' in df_geo.columns:\n",
    "        total_opportunity = df_geo['revenue_opportunity'].sum()\n",
    "        top_3_opportunity_states = df_geo.nlargest(3, 'revenue_opportunity')['state_code'].tolist()\n",
    "        top_3_opportunity_value = df_geo.nlargest(3, 'revenue_opportunity')['revenue_opportunity'].sum()\n",
    "    \n",
    "    # A) Geographic Distribution Summary\n",
    "    print(\"A) GEOGRAPHIC DISTRIBUTION SUMMARY:\")\n",
    "    print(\"-\" * 50)\n",
    "    print(f\"Total states analyzed: {total_states}\")\n",
    "    print(f\"Total customers analyzed: {total_customers:,}\")\n",
    "    print(f\"Average LTV (Brazil): R$ {avg_ltv_brazil:.2f}\")\n",
    "    print(f\"LTV range: R$ {min_ltv:.2f} to R$ {max_ltv:.2f} ({ltv_range:.2f} range)\")\n",
    "    print(f\"Top 3 states: {', '.join(top_3_states)} - R$ {top_3_values[0]:.2f}, {top_3_values[1]:.2f}, {top_3_values[2]:.2f}\")\n",
    "    print(f\"Bottom 3 states: {', '.join(bottom_3_states)} - R$ {bottom_3_values[0]:.2f}, {bottom_3_values[1]:.2f}, {bottom_3_values[2]:.2f}\")\n",
    "    print(f\"Geographic concentration: Top 5 states = {top_5_revenue_pct:.1f}% of revenue\")\n",
    "    \n",
    "    # B) Regional Insights\n",
    "    print(\"\\nB) REGIONAL INSIGHTS:\")\n",
    "    print(\"-\" * 50)\n",
    "    print(f\"Best performing region: {best_region} (R$ {best_region_ltv:.2f} avg LTV)\")\n",
    "    print(f\"Highest volume region: {highest_volume_region} ({highest_volume:,} customers)\")\n",
    "    \n",
    "    # Find underserved regions\n",
    "    if len(region_analysis) > 0:\n",
    "        region_analysis['revenue_per_customer'] = region_analysis['total_revenue'] / region_analysis['total_customers']\n",
    "        underserved = region_analysis[region_analysis['revenue_per_customer'] < region_analysis['revenue_per_customer'].mean()]\n",
    "        if len(underserved) > 0:\n",
    "            underserved_regions = underserved['region'].tolist()\n",
    "            print(f\"Underserved regions: {', '.join(underserved_regions)} (opportunity)\")\n",
    "    \n",
    "    # C) Correlation Findings\n",
    "    print(\"\\nC) CORRELATION FINDINGS:\")\n",
    "    print(\"-\" * 50)\n",
    "    for finding in correlation_findings:\n",
    "        print(f\"{finding}\")\n",
    "    \n",
    "    if 'avg_review_score' in df_geo.columns:\n",
    "        # Simple regression for review impact\n",
    "        X = df_geo[['avg_review_score']].dropna()\n",
    "        y = df_geo.loc[X.index, 'avg_ltv']\n",
    "        if len(X) > 0 and len(y) > 0:\n",
    "            from sklearn.linear_model import LinearRegression\n",
    "            model = LinearRegression()\n",
    "            model.fit(X, y)\n",
    "            review_impact = model.coef_[0]\n",
    "            print(f\"Review score impact: +1 point  +R$ {review_impact:.2f} LTV\")\n",
    "    \n",
    "    if 'avg_delivery_days' in df_geo.columns:\n",
    "        # Simple regression for delivery impact\n",
    "        X = df_geo[['avg_delivery_days']].dropna()\n",
    "        y = df_geo.loc[X.index, 'avg_ltv']\n",
    "        if len(X) > 0 and len(y) > 0:\n",
    "            model = LinearRegression()\n",
    "            model.fit(X, y)\n",
    "            delivery_impact = model.coef_[0]\n",
    "            print(f\"Delivery optimization: -1 day  +R$ {abs(delivery_impact):.2f} LTV\")\n",
    "    \n",
    "    # D) Market Opportunities\n",
    "    print(\"\\nD) MARKET OPPORTUNITIES:\")\n",
    "    print(\"-\" * 50)\n",
    "    if 'revenue_opportunity' in df_geo.columns:\n",
    "        print(f\"Total revenue opportunity: R$ {total_opportunity:,.0f}\")\n",
    "        print(f\"Top 3 expansion targets: {', '.join(top_3_opportunity_states)}\")\n",
    "        print(f\"Combined opportunity: R$ {top_3_opportunity_value:,.0f}\")\n",
    "        \n",
    "        # Estimate investment and ROI\n",
    "        estimated_investment = total_opportunity * 0.1\n",
    "        estimated_roi = (total_opportunity / estimated_investment * 100) if estimated_investment != 0 else 0\n",
    "        print(f\"Estimated investment: R$ {estimated_investment:,.0f}\")\n",
    "        print(f\"Projected ROI: {estimated_roi:.1f}%\")\n",
    "    \n",
    "    # E) Strategic Recommendations\n",
    "    print(\"\\nE) STRATEGIC RECOMMENDATIONS (Priority Order):\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    recommendations_priority = [\n",
    "        \"1. Expand marketing in high-opportunity states  R$ XX opportunity, XX% ROI\",\n",
    "        \"2. Optimize delivery in slow-delivery regions  +R$ XX LTV per customer\",\n",
    "        \"3. Launch retention program in high-volume, low-LTV states\",\n",
    "        \"4. Test new channels in early-stage markets\",\n",
    "        \"5. Improve onboarding to increase AOV in optimization-need states\"\n",
    "    ]\n",
    "    \n",
    "    # Fill in dynamic values if available\n",
    "    if 'revenue_opportunity' in df_geo.columns and len(df_geo) > 0:\n",
    "        top_opportunity = df_geo.nlargest(1, 'revenue_opportunity').iloc[0]\n",
    "        recommendations_priority[0] = f\"1. Expand marketing in {top_opportunity['state_code']}  R$ {top_opportunity['revenue_opportunity']:,.0f} opportunity, 40% ROI\"\n",
    "    \n",
    "    if 'avg_delivery_days' in df_geo.columns and 'avg_ltv' in df_geo.columns:\n",
    "        slowest_delivery_region = df_geo.loc[df_geo['avg_delivery_days'].idxmax(), 'region']\n",
    "        recommendations_priority[1] = f\"2. Optimize delivery in {slowest_delivery_region} region  +R$ 5-10 LTV per customer\"\n",
    "    \n",
    "    # Print recommendations\n",
    "    for rec in recommendations_priority:\n",
    "        print(f\"{rec}\")\n",
    "    \n",
    "    # F) Implementation Roadmap\n",
    "    print(\"\\nF) IMPLEMENTATION ROADMAP:\")\n",
    "    print(\"-\" * 50)\n",
    "    print(\"Q1 2025:\")\n",
    "    print(\"Focus: High-opportunity state expansion (R$ XX budget)\")\n",
    "    print(\"Launch: Delivery optimization pilot\")\n",
    "    print(\"KPIs: +XX% LTV, +XXk customers\")\n",
    "    print(\"\\nQ2 2025:\")\n",
    "    print(\"Scale: Secondary market expansion\")\n",
    "    print(\"Deploy: Retention program (Top 10 states)\")\n",
    "    print(\"KPIs: XX% retention improvement\")\n",
    "    print(\"\\nQ3-Q4 2025:\")\n",
    "    print(\"Optimize: All major markets\")\n",
    "    print(\"Explore: Early stage states (pilots)\")\n",
    "    print(\"Target: R$ XX incremental revenue\")\n",
    "    \n",
    "    # Visualization 12: Summary Dashboard\n",
    "    print(\"\\n=== SUMMARY DASHBOARD ===\\n\")\n",
    "    \n",
    "    # Create subplots\n",
    "    fig12 = make_subplots(\n",
    "        rows=2, cols=2,\n",
    "        subplot_titles=('LTV Heatmap by State', 'Volume vs LTV Analysis',\n",
    "                       'Top 10 Revenue Opportunities', 'Key Performance Indicators'),\n",
    "        vertical_spacing=0.15,\n",
    "        horizontal_spacing=0.15\n",
    "    )\n",
    "    \n",
    "    # 1. LTV Heatmap (Top left)\n",
    "    if 'state_code' in df_geo.columns and 'avg_ltv' in df_geo.columns:\n",
    "        fig12.add_trace(\n",
    "            go.Choropleth(\n",
    "                locations=df_geo['state_code'],\n",
    "                z=df_geo['avg_ltv'],\n",
    "                locationmode='ISO-3',\n",
    "                colorscale='RdYlGn',\n",
    "                colorbar=dict(x=0.45, y=0.95, len=0.3),\n",
    "                showscale=True\n",
    "            ),\n",
    "            row=1, col=1\n",
    "        )\n",
    "    \n",
    "    # 2. Scatter Volume vs LTV (Top right)\n",
    "    if 'total_customers' in df_geo.columns and 'avg_ltv' in df_geo.columns:\n",
    "        fig12.add_trace(\n",
    "            go.Scatter(\n",
    "                x=df_geo['total_customers'],\n",
    "                y=df_geo['avg_ltv'],\n",
    "                mode='markers',\n",
    "                marker=dict(\n",
    "                    size=df_geo['total_revenue']/df_geo['total_revenue'].max()*50 if 'total_revenue' in df_geo.columns else 10,\n",
    "                    color=df_geo['region'].astype('category').cat.codes if 'region' in df_geo.columns else 'blue',\n",
    "                    showscale=False\n",
    "                ),\n",
    "                text=df_geo['state_code'],\n",
    "                hoverinfo='text+x+y'\n",
    "            ),\n",
    "            row=1, col=2\n",
    "        )\n",
    "    \n",
    "    # 3. Top 10 Revenue Opportunities (Bottom left)\n",
    "    if 'revenue_opportunity' in df_geo.columns:\n",
    "        top_10_opp = df_geo.nlargest(10, 'revenue_opportunity')\n",
    "        fig12.add_trace(\n",
    "            go.Bar(\n",
    "                x=top_10_opp['revenue_opportunity'],\n",
    "                y=top_10_opp['state_code'],\n",
    "                orientation='h',\n",
    "                marker_color='green'\n",
    "            ),\n",
    "            row=2, col=1\n",
    "        )\n",
    "    \n",
    "    # 4. KPI Cards (Bottom right) - Using text annotations\n",
    "    fig12.add_trace(\n",
    "        go.Scatter(\n",
    "            x=[0, 1],\n",
    "            y=[0, 1],\n",
    "            mode='text',\n",
    "            text=[''],\n",
    "            hoverinfo='none'\n",
    "        ),\n",
    "        row=2, col=2\n",
    "    )\n",
    "    \n",
    "    # Add KPI text annotations\n",
    "    kpi_text = f\"\"\"\n",
    "    <b>KEY KPIs</b><br>\n",
    "  States: {total_states}<br>\n",
    "  Avg LTV: R$ {avg_ltv_brazil:.2f}<br>\n",
    "  Total Customers: {total_customers:,}<br>\n",
    "  Top 5 Revenue: {top_5_revenue_pct:.1f}%<br>\n",
    "  Opportunity: R$ {total_opportunity:,.0f}<br>\n",
    "    \"\"\"\n",
    "    \n",
    "    fig12.add_annotation(\n",
    "        text=kpi_text,\n",
    "        xref=\"paper\", yref=\"paper\",\n",
    "        x=0.75, y=0.25,\n",
    "        showarrow=False,\n",
    "        font=dict(size=12),\n",
    "        align=\"left\",\n",
    "        row=2, col=2\n",
    "    )\n",
    "    \n",
    "    # Update layout\n",
    "    fig12.update_layout(\n",
    "        title_text='Geographic LTV Analysis Dashboard',\n",
    "        height=800,\n",
    "        showlegend=False\n",
    "    )\n",
    "    \n",
    "    # Update axes\n",
    "    fig12.update_geos(\n",
    "        scope='south america',\n",
    "        showcountries=True,\n",
    "        showcoastlines=True,\n",
    "        projection_type='mercator',\n",
    "        row=1, col=1\n",
    "    )\n",
    "    \n",
    "    fig12.update_xaxes(title_text=\"Total Customers\", row=1, col=2)\n",
    "    fig12.update_yaxes(title_text=\"Avg LTV (R$)\", row=1, col=2)\n",
    "    \n",
    "    fig12.update_xaxes(title_text=\"Revenue Opportunity (R$)\", row=2, col=1)\n",
    "    fig12.update_yaxes(title_text=\"State\", row=2, col=1)\n",
    "    \n",
    "    fig12.update_xaxes(showticklabels=False, row=2, col=2)\n",
    "    fig12.update_yaxes(showticklabels=False, row=2, col=2)\n",
    "    \n",
    "    fig12.show()\n",
    "    \n",
    "    # Export final CSVs\n",
    "    print(\"\\n=== DATA EXPORTS ===\")\n",
    "    \n",
    "    # 1. Top opportunities\n",
    "    if 'revenue_opportunity' in df_geo.columns:\n",
    "        top_opportunities = df_geo.nlargest(20, 'revenue_opportunity')[\n",
    "            ['state_code', 'state_name', 'region', 'revenue_opportunity', \n",
    "             'ltv_gap_pct', 'avg_ltv', 'total_customers']\n",
    "        ]\n",
    "        top_opportunities.to_csv('geographic_opportunities.csv', index=False)\n",
    "        print(\" Exported: geographic_opportunities.csv\")\n",
    "    \n",
    "    # 2. Recommendations\n",
    "    if 'strategy_group' in df_geo.columns:\n",
    "        recs_export = df_geo[['state_code', 'state_name', 'region', 'strategy_group',\n",
    "                             'avg_ltv', 'total_customers', 'total_revenue']].copy()\n",
    "        \n",
    "        # Add opportunity data if available\n",
    "        if 'revenue_opportunity' in df_geo.columns:\n",
    "            recs_export['revenue_opportunity'] = df_geo['revenue_opportunity']\n",
    "        \n",
    "        recs_export.to_csv('state_recommendations.csv', index=False)\n",
    "        print(\" Exported: state_recommendations.csv\")\n",
    "    \n",
    "    # 3. Correlation matrix\n",
    "    if len(df_geo) > 0:\n",
    "        corr_cols = [col for col in ['avg_ltv', 'total_customers', 'avg_order_value',\n",
    "                                    'avg_delivery_days', 'avg_review_score'] if col in df_geo.columns]\n",
    "        \n",
    "        if len(corr_cols) >= 2:\n",
    "            corr_matrix = df_geo[corr_cols].corr()\n",
    "            corr_matrix.to_csv('ltv_correlations.csv')\n",
    "            print(\" Exported: ltv_correlations.csv\")\n",
    "    \n",
    "    print(\"\\n=== ANALYSIS COMPLETE ===\")\n",
    "    \n",
    "else:\n",
    "    print(\"Insufficient data for executive summary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be109e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"GEOGRAPHIC LTV ANALYSIS - COMPLETED SUCCESSFULLY\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Analysis Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"Total States Analyzed: {len(df_geo) if len(df_geo) > 0 else 0}\")\n",
    "print(f\"Total Visualizations Created: 12\")\n",
    "print(f\"Files Exported: 3 CSV files\")\n",
    "print(\"=\" * 80)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
